# Pairwise comparsion
TukeyHSD(res_aov)
PA <- c(70, 102, 118, 104, 98, 107, 100, 87, 117, 110)
PB <- c(97, 74, 56, 111, 95, 88, 82, 77, 86, 91)
PC <- c(96, 79, 96, 98, 102, 102, 108, 91, 120, 107)
PD <- c(95, 100, 90, 99, 103, 109, 108, 101, 98, 113)
# Test for normality
shapiro.test(c(PA,PB,PC,PD))
shapiro.test(PA)
shapiro.test(PB)
shapiro.test(PC)
shapiro.test(PD)
# Randomness test
runs.test(PA)
runs.test(PB)
runs.test(PC)
runs.test(PD)
# after group has one outliner
# use dixon.test()
dixon.test(PA)
dixon.test(PB)
dixon.test(PC)
dixon.test(PD)
# Make data frame
phytoplankton_data  <- data.frame(O2=c(PA, PB, PC, PD),
group=c(rep("A", length(PA)),
rep("B", length(PB)),
rep("C", length(PC)),
rep("D", length(PD)) ))
# Do the ANOVA
oneway.test(O2 ~ group, data=phytoplankton_data, var.equal=T)
res_aov <- aov(O2 ~ group, data=phytoplankton_data)
summary(res_aov)
# Check assumptions, not bad
par(mfrow=c(2,2))
plot(res_aov)
par(mfrow=c(1,1))
# Pairwise comparsion
TukeyHSD(res_aov)
#/////////////////////////////////////////////////////////////////////
# 3.3
#/////////////////////////////////////////////////////////////////////
Pressure    <- c(999.9,  999.4,  999.1,  999.6,  998.5,
1000.8, 1002.0,  999.4, 1002.7, 1003.2,
996.6, 1003.0, 1004.3, 1000.4,  998.3)
Temperature <- c(20.2, 21.1, 19.3, 17.5, 16.9, 22.5, 13.6,
21.2, 23.5, 18.6, 25.0, 23.6, 17.0, 27.2, 14.1)
Humidity    <- c(44, 56, 20, 31, 60, 48, 76, 65, 60,
74, 68, 69, 50, 36, 63)
Traffic     <- c(357, 256, 270, 541, 254, 337, 411, 280,
289,  88, 275, 358, 380, 268, 523)
AQI         <- c(367, 307, 280, 388, 268, 347, 308, 247,
289, 200, 329, 385, 337, 336, 394)
# Make data frame
AQI_data  <- data.frame(cbind(AQI,Pressure,Temperature,Humidity,Traffic))
str(AQI_data)
# Plot scatter plots
ggpairs(AQI_data,columns=1:5)
# no clear multicollinearity
# Randomness test
runs.test(AQI_data$AQI)
# use dixon.test() to check outliers
dixon.test(AQI_data$AQI)
# no outliers
# Build the full model
full_model <- lm(AQI ~ Pressure + Temperature + Humidity + Traffic )
summary(full_model)
# Test all possible subsets
output      <- ols_step_all_possible(full_model)
# Print results from all possible subsets
output
# Select the best model
ols_step_best_subset(full_model)
ols_step_backward_aic(full_model, details=F)
ols_step_forward_aic(full_model, details=F)
# This is the best model
reg <- lm(AQI ~ Temperature + Traffic )
summary(reg)
Pressure    <- c(999.9,  999.4,  999.1,  999.6,  998.5,
1000.8, 1002.7,  999.4, 1002.7, 1003.2,
996.6, 1003.0, 1004.3, 1000.4,  998.3)
Temperature <- c(20.2, 21.1, 19.3, 17.5, 16.9, 22.5, 13.6,
21.2, 23.5, 18.6, 25.7, 23.6, 17.0, 27.2, 14.1)
Humidity    <- c(44, 56, 20, 31, 64, 48, 76, 65, 60,
74, 68, 69, 50, 36, 63)
Traffic     <- c(357, 256, 270, 541, 254, 337, 411, 280,
289,  91, 275, 358, 380, 268, 523)
AQI         <- c(367, 307, 280, 388, 268, 347, 308, 247,
289, 200, 329, 385, 337, 336, 397)
# Make data frame
AQI_data  <- data.frame(cbind(AQI,Pressure,Temperature,Humidity,Traffic))
str(AQI_data)
# Plot scatter plots
ggpairs(AQI_data,columns=1:5)
# no clear multicollinearity
# Randomness test
runs.test(AQI_data$AQI)
# use dixon.test() to check outliers
dixon.test(AQI_data$AQI)
# no outliers
# Build the full model
full_model <- lm(AQI ~ Pressure + Temperature + Humidity + Traffic )
summary(full_model)
# Test all possible subsets
output      <- ols_step_all_possible(full_model)
# Print results from all possible subsets
output
# Select the best model
ols_step_best_subset(full_model)
ols_step_backward_aic(full_model, details=F)
ols_step_forward_aic(full_model, details=F)
# This is the best model
reg <- lm(AQI ~ Temperature + Traffic )
summary(reg)
# New point
new_points <- data.frame(Pressure = c(1002.0,1001.0 ), Temperature = c(26.0,15.0 ),
Humidity = c(75, 55), Traffic = c(430,310 ) )
# Make prediction for the mean or individual response
predict(reg, newdata = new_points, interval="prediction", level=0.95)
predict(reg, newdata = new_points, interval="confidence", level=0.95)
# Read data
Keeling_Data     <- read.csv(file = "co2_monthly_mlo_1958_2025.csv", header = T)
# Read data
Keeling_Data     <- read.csv(file = "co2_monthly_mlo_1958_2025.csv", header = T)
# Handel missing values
Keeling_Data$co2[which(Keeling_Data$co2<0)] <- NA
for(i in 1:length(Keeling_Data$co2)){
if( is.na(Keeling_Data$co2[i])){
Keeling_Data$co2[i] <- mean(Keeling_Data$co2[(i-2):(i+2)],na.rm=T )
}
}
# Apply the ts() function
co2 <- ts(Keeling_Data$co2, start=c(1958,3), frequency=12)
# Quick plot
plot(co2, type="l")
# Automated forecasting using an SARIMA model
best_model <- auto.arima(co2)
# Show details of the ARIMA model
best_model
# Number of days to predict
months_forecast  <- 10
# Number of include in the plot
months_in_plot   <- 30
# Make predictions using the forecast() function
forecast <- forecast(best_model, months_forecast)
# Plot
plot(forecast(best_model, months_forecast), include=months_in_plot,
xlab="Time", ylab="CO2", type="o", lwd=2)
forecast
co2
Keeling_Data
tail(Keeling_Data)
Keeling_Data     <- read.csv(file = "co2_monthly_mlo_1958_2025.csv", header = T)
# Handel missing values
Keeling_Data$co2[which(Keeling_Data$co2<0)] <- NA
for(i in 1:length(Keeling_Data$co2)){
if( is.na(Keeling_Data$co2[i])){
Keeling_Data$co2[i] <- mean(Keeling_Data$co2[(i-2):(i+2)],na.rm=T )
}
}
tail(Keeling_Data)
# Apply the ts() function
co2 <- ts(Keeling_Data$co2, start=c(1958,3), frequency=12)
# Quick plot
plot(co2, type="l")
# Automated forecasting using an SARIMA model
best_model <- auto.arima(co2)
# Show details of the ARIMA model
best_model
#-------------------------------------------------------------------------------
# Make predictions
# Number of days to predict
months_forecast  <- 10
# Number of include in the plot
months_in_plot   <- 30
# Make predictions using the forecast() function
forecast <- forecast(best_model, months_forecast)
# Plot
plot(forecast(best_model, months_forecast), include=months_in_plot,
xlab="Time", ylab="CO2", type="o", lwd=2)
forecast
forecast(best_model, months_forecast)
# Verify, 2025-02, 2025-03, 2025-04
predicted_co2 <- c(427.5549, 428.1791, 429.6716)
obs_co2       <- c(427.09,	428.15,	429.64)
(predicted_co2-obs_co2)/obs_co2*100
# Read data
Keeling_Data     <- read.csv(file = "co2_monthly_mlo_1958_2024.csv", header = T)
# Handel missing values
Keeling_Data$co2[which(Keeling_Data$co2<0)] <- NA
for(i in 1:length(Keeling_Data$co2)){
if( is.na(Keeling_Data$co2[i])){
Keeling_Data$co2[i] <- mean(Keeling_Data$co2[(i-2):(i+2)],na.rm=T )
}
}
# Apply the ts() function
co2 <- ts(Keeling_Data$co2, start=c(1958,3), frequency=12)
tail(Keeling_Data)
# Apply the ts() function
co2 <- ts(Keeling_Data$co2, start=c(1958,3), frequency=12)
# Quick plot
plot(co2, type="l")
# Automated forecasting using an SARIMA model
best_model <- auto.arima(co2)
# Show details of the ARIMA model
best_model
#-------------------------------------------------------------------------------
# Make predictions
# Number of days to predict
months_forecast  <- 6
# Number of include in the plot
months_in_plot   <- 20
# Make predictions using the forecast() function
forecast <- forecast(best_model, months_forecast)
# Plot
plot(forecast(best_model, months_forecast), include=months_in_plot,
xlab="Time", ylab="CO2", type="o", lwd=2)
forecast
# Verify, 2025-01, 2025-02, 2025-03, 2025-04
predicted_co2 <- c(426.5521, 427.5549, 428.1791, 429.6716)
obs_co2       <- c(426.65, 427.09,	428.15,	429.64)
(predicted_co2-obs_co2)/obs_co2*100
# Number of days to predict
months_forecast  <- 6
# Number of include in the plot
months_in_plot   <- 24
# Make predictions using the forecast() function
forecast <- forecast(best_model, months_forecast)
# Plot
plot(forecast(best_model, months_forecast), include=months_in_plot,
xlab="Time", ylab="CO2", type="o", lwd=2)
# Number of days to predict
months_forecast  <- 12
# Number of include in the plot
months_in_plot   <- 24
# Make predictions using the forecast() function
forecast <- forecast(best_model, months_forecast)
# Plot
plot(forecast(best_model, months_forecast), include=months_in_plot,
xlab="Time", ylab="CO2", type="o", lwd=2)
library(dplyr)
library(lubridate)
library(forecast)
# Read in the COVID-19 data
COVID_data <- read.csv(file = "COVID_2020_data.csv", header = T)
# Check the variable names
head(COVID_data)
# Convert the data.frame to a tibble
COVID_tbl <- as_tibble(COVID_data)
# Show data
COVID_tbl
# Get global daily new cases
COVID_tbl <- COVID_tbl %>%
mutate(dateRep = as.Date(dateRep,format='%d/%m/%Y')) %>%
group_by(dateRep) %>%
summarize(global_cases = sum(cases))
# Show data
COVID_tbl
# Quick plot
plot(COVID_tbl$dateRep,COVID_tbl$global_cases,
type="l", xlab="Date", ylab="Global cases")
# Filter the data, only use data from April 01
COVID_tbl <- COVID_tbl %>%
filter(dateRep >= as.Date("2020-04-01"))
# Show data
COVID_tbl
# Start date of the time series, read from the .csv file
Date_start <- as.Date("2020-04-01")
# End date of the time series, read from the .csv file
Date_end   <- as.Date("2020-11-09")
# Get the Julian Day of the start and end date
JD_start   <- yday(Date_start)
JD_end     <- yday(Date_end)
N_days     <- JD_end - JD_start + 1
# Convert the vector data to a time series
global_cases_ts <- ts(COVID_tbl$global_cases[1:N_days], start=c(2020,JD_start), frequency=365)
# The indicator of the time series
inds            <- seq(Date_start, Date_end, by="day")
# Check structure
str(global_cases_ts)
# Plot time series
plot(inds, global_cases_ts, type="l")
# Plot time series
plot(inds, global_cases_ts, type="l")
# Data transform with log
global_cases_ts_log <- log(global_cases_ts)
# Plot time series
plot(inds, global_cases_ts_log, type="l")
# Check acf and pacf
acf(global_cases_ts_log)
pacf(global_cases_ts_log)
# Take the diff, d=1
global_cases_ts_log_d1 <- diff(global_cases_ts_log)
# Plot time series
plot(global_cases_ts_log_d1,type="l")
# Check acf and pacf
acf(global_cases_ts_log_d1)
pacf(global_cases_ts_log_d1)
# Automated forecasting using an ARIMA model
model <- auto.arima(global_cases_ts_log)
# Show details of the ARIMA model
model
# Number of days to predict
days_forecast  <- 30
# Number of include in the plot
days_in_plot   <- 30
# Make predictions using the forecast() function
forecast_30days <- forecast(model, days_forecast)
# Plot
plot(forecast_30days, include=days_in_plot,
xlab="Time", ylab="log(global cases)", type="o", lwd=2)
# Get predicted values on Nov 10, 2020
day_forward <- yday(as.Date("2020-11-10")) - yday(Date_end)
exp(forecast_30days$mean[day_forward])
exp(forecast_30days$lower[day_forward,1])
exp(forecast_30days$upper[day_forward,1])
# Get predicted values on Nov 30, 2020
day_forward <- yday(as.Date("2020-11-30")) - yday(Date_end)
exp(forecast_30days$mean[day_forward])
exp(forecast_30days$lower[day_forward,1])
exp(forecast_30days$upper[day_forward,1])
# Section 19
# COVID-19 daily cases
# Load libraries
library(dplyr)
library(lubridate)
library(forecast)
#-------------------------------------------------------------------------------
# 1. Load the daily new cases data
#-------------------------------------------------------------------------------
# Read in the COVID-19 data
COVID_data <- read.csv(file = "COVID_2020_data.csv", header = T)
# Check the variable names
head(COVID_data)
head(COVID_data)
# Convert the data.frame to a tibble
COVID_tbl <- as_tibble(COVID_data)
COVID_tbl
# Get global daily new cases
COVID_tbl <- COVID_tbl %>%
mutate(dateRep = as.Date(dateRep,format='%d/%m/%Y')) %>%
group_by(dateRep) %>%
summarize(global_cases = sum(cases))
# Show data
COVID_tbl
#-------------------------------------------------------------------------------
# 3. Plot the data
#-------------------------------------------------------------------------------
# Quick plot
plot(COVID_tbl$dateRep, COVID_tbl$global_cases,
type="l", xlab="Date", ylab="Global cases")
#-------------------------------------------------------------------------------
# 3. Plot the data
#-------------------------------------------------------------------------------
# Quick plot
plot(COVID_tbl$dateRep, COVID_tbl$global_cases,
type="l", xlab="Date", ylab="Global cases")
#-------------------------------------------------------------------------------
# 3. Plot the data
#-------------------------------------------------------------------------------
# Quick plot
plot(COVID_tbl$dateRep, COVID_tbl$global_cases,
type="l", xlab="Date", ylab="Global cases")
# Filter the data, only use data from April 01
COVID_tbl <- COVID_tbl %>%
filter(dateRep >= as.Date("2020-04-01"))
# Show data
COVID_tbl
# Start date of the time series, read from the .csv file
Date_start <- as.Date("2020-04-01")
# End date of the time series, read from the .csv file
Date_end   <- as.Date("2020-11-09")
# Get the Julian Day of the start and end date
JD_start   <- yday(Date_start)
JD_end     <- yday(Date_end)
N_days     <- JD_end - JD_start + 1
JD_start
JD_end
# Convert the vector data to a time series
global_cases_ts <- ts(COVID_tbl$global_cases[1:N_days], start=c(2020,JD_start), frequency=365)
# The indicator of the time series
inds            <- seq(Date_start, Date_end, by="day")
# Check structure
str(global_cases_ts)
# Plot time series
plot(inds, global_cases_ts, type="l")
# Quick plot
plot(COVID_tbl$dateRep, COVID_tbl$global_cases,
type="l", xlab="Date", ylab="Global cases")
# Filter the data, only use data from April 01
COVID_tbl <- COVID_tbl %>%
filter(dateRep >= as.Date("2020-04-01"))
# Show data
COVID_tbl
# Start date of the time series, read from the .csv file
Date_start <- as.Date("2020-04-01")
# End date of the time series, read from the .csv file
Date_end   <- as.Date("2020-11-09")
# Get the Julian Day of the start and end date
JD_start   <- yday(Date_start)
JD_end     <- yday(Date_end)
JD_start
JD_end
N_days     <- JD_end - JD_start + 1
N_days
# Convert the vector data to a time series
global_cases_ts <- ts(COVID_tbl$global_cases[1:N_days],
start=c(2020,JD_start), frequency=365)
global_cases_ts
# The indicator of the time series
inds            <- seq(Date_start, Date_end, by="day")
inds
# Check structure
str(global_cases_ts)
# Plot time series
plot(inds, global_cases_ts, type="l")
# Data transform with log
global_cases_ts_log <- log(global_cases_ts)
# Plot time series
plot(inds, global_cases_ts_log, type="l")
# Check acf and pacf
acf(global_cases_ts_log)
pacf(global_cases_ts_log)
# Take the diff, d=1
global_cases_ts_log_d1 <- diff(global_cases_ts_log)
# Plot time series
plot(global_cases_ts_log_d1,type="l")
# Take the diff, d=1
global_cases_ts_log_d1 <- diff(global_cases_ts_log)
global_cases_ts_log_d2 <- diff(global_cases_ts_log_d1)
# Plot time series
plot(global_cases_ts_log_d2,type="l")
# Plot time series
plot(global_cases_ts_log_d1,type="l")
# Check acf and pacf
acf(global_cases_ts_log_d1)
pacf(global_cases_ts_log_d1)
# Automated forecasting using an ARIMA model
best_model <- auto.arima(global_cases_ts_log)
# Show details of the ARIMA model
best_model
# Number of days to predict
days_forecast  <- 30
# Number of include in the plot
days_in_plot   <- 30
# Make predictions using the forecast() function
forecast_30days <- forecast(best_model, days_forecast)
# Plot
plot(forecast(best_model, days_forecast), include=days_in_plot,
xlab="Time", ylab="log(global cases)", type="o", lwd=2)
# Number of days to predict
days_forecast  <- 60
# Number of include in the plot
days_in_plot   <- 20
# Make predictions using the forecast() function
forecast_30days <- forecast(best_model, days_forecast)
# Plot
plot(forecast(best_model, days_forecast), include=days_in_plot,
xlab="Time", ylab="log(global cases)", type="o", lwd=2)
# Number of days to predict
days_forecast  <- 60
# Number of include in the plot
days_in_plot   <- 100
# Make predictions using the forecast() function
forecast_30days <- forecast(best_model, days_forecast)
# Plot
plot(forecast(best_model, days_forecast), include=days_in_plot,
xlab="Time", ylab="log(global cases)", type="o", lwd=2)
# Number of days to predict
days_forecast  <- 20
# Number of include in the plot
days_in_plot   <- 20
# Make predictions using the forecast() function
forecast_30days <- forecast(best_model, days_forecast)
# Plot
plot(forecast(best_model, days_forecast), include=days_in_plot,
xlab="Time", ylab="log(global cases)", type="o", lwd=2)
# Number of days to predict
days_forecast  <- 30
# Number of include in the plot
days_in_plot   <- 20
# Make predictions using the forecast() function
forecast_30days <- forecast(best_model, days_forecast)
# Plot
plot(forecast(best_model, days_forecast), include=days_in_plot,
xlab="Time", ylab="log(global cases)", type="o", lwd=2)
# Get predicted values on Nov 10, 2020
day_forward <- yday(as.Date("2020-11-10")) - yday(Date_end)
exp(forecast_30days$mean[day_forward])
exp(forecast_30days$lower[day_forward,1])
exp(forecast_30days$upper[day_forward,1])
forecast_30days
exp(forecast_30days$mean[day_forward])
exp(forecast_30days$lower[day_forward,1])
exp(forecast_30days$upper[day_forward,1])
# Get predicted values on Nov 30, 2020
day_forward <- yday(as.Date("2020-11-30")) - yday(Date_end)
exp(forecast_30days$mean[day_forward])
exp(forecast_30days$lower[day_forward,1])
exp(forecast_30days$upper[day_forward,1])
# Nov 10
(500063.9 - 502287)/502287 * 100
# Nov 30
(613331.2 - 516616)/516616 * 100
setwd("D://repo/ese335")
rmarkdown::render_site()
rmarkdown::render_site()
rmarkdown::render_site()
rmarkdown::render_site()
setwd("D://repo/ese335")
rmarkdown::render_site()
rmarkdown::render_site()
