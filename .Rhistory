oneway.test(O2 ~ group, data=phytoplankton_data, var.equal=T)
res_aov <- aov(O2 ~ group, data=phytoplankton_data)
summary(res_aov)
# Check assumptions, not bad
par(mfrow=c(2,2))
plot(res_aov)
# Pairwise comparsion
TukeyHSD(res_aov)
par(mfrow=c(1,1))
# Perform the Kruskalâ€“Wallis test
kruskal.test(O2 ~ group, data = phytoplankton_data)
dunnTest(O2 ~ group, data=phytoplankton_data, method="bh")
#/////////////////////////////////////////////////////////////////////
# 3.3
#/////////////////////////////////////////////////////////////////////
#/////////////////////////////////////////////////////////////////////
# 3.3
#/////////////////////////////////////////////////////////////////////
Pressure    <- c(999.9,  999.4,  999.1,  999.6,  998.5,
1000.8, 1002.0,  999.4, 1002.7, 1003.2,
996.6, 1003.0, 1004.3, 1000.4,  998.3)
Temperature <- c(20.2, 21.1, 19.3, 17.5, 16.9, 22.5, 13.6,
21.2, 23.5, 18.6, 25.0, 23.6, 17.0, 27.2, 14.1)
Humidity    <- c(44, 56, 20, 31, 60, 48, 76, 65, 60,
74, 68, 69, 50, 36, 63)
Traffic     <- c(357, 256, 270, 541, 254, 337, 411, 280,
289,  88, 275, 358, 380, 268, 523)
AQI         <- c(377, 307, 280, 388, 268, 347, 308, 247,
289, 200, 329, 385, 337, 336, 384)
# Make data frame
AQI_data  <- data.frame(cbind(AQI,Pressure,Temperature,Humidity,Traffic))
str(AQI_data)
# Plot scatter plots
ggpairs(AQI_data,columns=1:5)
# no clear multicollinearity
# Randomness test
runs.test(AQI_data$AQI)
# use dixon.test() to check outliers
dixon.test(AQI_data$AQI)
# no outliers
# Build the full model
full_model <- lm(AQI ~ Pressure + Temperature + Humidity + Traffic )
summary(full_model)
# Test all possible subsets
output      <- ols_step_all_possible(full_model)
# Print results from all possible subsets
output
# Select the best model
ols_step_best_subset(full_model)
ols_step_backward_aic(full_model, details=F)
ols_step_forward_aic(full_model, details=F)
# This is the best model
reg <- lm(AQI ~ Temperature + Traffic )
# 24 Spring, 6.40475T + 0.48960*Traffic + 30.63780
# New point
new_points <- data.frame(Pressure = c(1003.0,1001.0 ), Temperature = c(25.0,15.0 ),
Humidity = c(75, 55), Traffic = c(450,310 ) )
# Make prediction for the mean or individual response
predict(reg, newdata = new_points, interval="prediction", level=0.95)
predict(reg, newdata = new_points, interval="confidence", level=0.95)
# This is the best model
reg <- lm(AQI ~ Temperature + Traffic )
summary(reg)
# Make prediction for the mean or individual response
predict(reg, newdata = new_points, interval="prediction", level=0.95)
# New point
new_points <- data.frame(Pressure = c(1003.0,1001.0 ), Temperature = c(25.0,15.0 ),
Humidity = c(75, 55), Traffic = c(450,300 ) )
# Make prediction for the mean or individual response
predict(reg, newdata = new_points, interval="prediction", level=0.95)
predict(reg, newdata = new_points, interval="confidence", level=0.95)
# Load libraries
library(randtests)
library(EnvStats)
library(outliers)
library(FSA)
library(ggplot2)
library(GGally)
library(olsrr)
library(dplyr)
library(lubridate)
library(forecast)
#/////////////////////////////////////////////////////////////////////
# 3.1
#/////////////////////////////////////////////////////////////////////
before <- c(6.26, 	4.13, 	5.09, 	4.71, 	6.01, 	5.53, 	4.94, 	5.97,
5.09, 	4.69, 	5.49, 	6.65, 	6.17, 	7.83, 	6.22, 	5.08,
6.45, 	6.40, 	5.29, 	5.42, 	6.68, 	6.00, 	4.88, 	6.08,
4.82, 	8.97, 	5.88, 	6.19, 	5.86, 	5.01, 	5.81, 	7.63)
after <- c(6.12, 	4.59, 	5.33, 	5.83, 	5.34, 	5.37, 	5.29, 	5.55,
5.80, 	5.22, 	5.29, 	4.84, 	2.35, 	5.04, 	3.60, 	4.08,
5.11, 	5.76, 	5.48, 	4.96, 	5.51,	 4.46, 	5.52, 	5.35,
5.19, 	4.88, 	5.91, 	6.57,	6.74, 	5.18, 	5.98, 	5.61)
new <- after - before
shapiro.test(new)
# Test for normality
shapiro.test(before)
shapiro.test(after)
# Randomness test
runs.test(before)
runs.test(after)
# after group has one outliner
# use Rosner??s test to check outliers
rosnerTest(before)
rosnerTest(after)
# Remove the outliners
before_new <- c(6.26, 	4.13, 	5.09, 	4.71, 	6.01, 	5.53, 	4.94, 	5.97,
5.09, 	4.69, 	5.49, 	6.65, 	7.83, 	6.22, 	5.08,
6.45, 	6.40, 	5.29, 	5.42, 	6.68, 	6.00, 	4.88, 	6.08,
4.82, 	5.88, 	6.19, 	5.86, 	5.01, 	5.81, 	7.63)
after_new <-  c(6.12, 	4.59, 	5.33, 	5.83, 	5.34, 	5.37, 	5.29, 	5.55,
5.80, 	5.22, 	5.29, 	4.84, 	5.04, 	3.60, 	4.08,
5.11, 	5.76, 	5.48, 	4.96, 	5.51,	  4.46, 	5.52, 	5.35,
5.19, 	5.91, 	6.57,	  6.74, 	5.18, 	5.98, 	5.61)
# Check again
shapiro.test(before_new)
rosnerTest(before_new)
shapiro.test(after_new)
rosnerTest(after_new)
# Use pair t-test
# Use one-sided p-value
# Without the outliner
t.test(after_new,before_new,alternative = "less",paired = T)
# With the outliner
t.test(after,before,alternative = "less",paired = T)
# The student can also use the Mann-Whitney U test
wilcox.test(after, before, paired=T, alternative="less")
# So the data show the air purifier is useful in reducing indoor PM2.5
# p < 0.05
#/////////////////////////////////////////////////////////////////////
# 3.2
#/////////////////////////////////////////////////////////////////////
PA <- c(73, 102, 118, 104, 98, 107, 100, 87, 117, 111)
PB <- c(98, 74, 56, 111, 95, 88, 82, 77, 86, 92)
PC <- c(94, 79, 96, 98, 102, 102, 108, 91, 120, 105)
PD <- c(97, 100, 90, 99, 103, 109, 108, 101, 98, 115)
# Test for normality
shapiro.test(c(PA,PB,PC,PD))
shapiro.test(PA)
shapiro.test(PB)
shapiro.test(PC)
shapiro.test(PD)
# Randomness test
runs.test(PA)
runs.test(PB)
runs.test(PC)
runs.test(PD)
# after group has one outliner
# use dixon.test()
dixon.test(PA)
dixon.test(PB)
dixon.test(PC)
dixon.test(PD)
# Make data frame
phytoplankton_data  <- data.frame(O2=c(PA, PB, PC, PD),
group=c(rep("A", length(PA)),
rep("B", length(PB)),
rep("C", length(PC)),
rep("D", length(PD)) ))
# Do the ANOVA
oneway.test(O2 ~ group, data=phytoplankton_data, var.equal=T)
res_aov <- aov(O2 ~ group, data=phytoplankton_data)
summary(res_aov)
# Check assumptions, not bad
par(mfrow=c(2,2))
plot(res_aov)
par(mfrow=c(1,1))
# Pairwise comparsion
TukeyHSD(res_aov)
# Only B-A and D-B has significant difference.
#/////////////////////////////////////////////////////////////////////
# 3.3
#/////////////////////////////////////////////////////////////////////
Pressure    <- c(999.9,  999.4,  999.1,  999.6,  998.5,
1000.8, 1002.0,  999.4, 1002.7, 1003.2,
996.6, 1003.0, 1004.3, 1000.4,  998.3)
Temperature <- c(20.2, 21.1, 19.3, 17.5, 16.9, 22.5, 13.6,
21.2, 23.5, 18.6, 25.0, 23.6, 17.0, 27.2, 14.1)
Humidity    <- c(44, 56, 20, 31, 60, 48, 76, 65, 60,
74, 68, 69, 50, 36, 63)
Traffic     <- c(357, 256, 270, 541, 254, 337, 411, 280,
289,  88, 275, 358, 380, 268, 523)
AQI         <- c(367, 307, 280, 388, 268, 347, 308, 247,
289, 200, 329, 385, 337, 336, 394)
# Make data frame
AQI_data  <- data.frame(cbind(AQI,Pressure,Temperature,Humidity,Traffic))
str(AQI_data)
# Plot scatter plots
ggpairs(AQI_data,columns=1:5)
# no clear multicollinearity
# Randomness test
runs.test(AQI_data$AQI)
# use dixon.test() to check outliers
dixon.test(AQI_data$AQI)
# no outliers
# Build the full model
full_model <- lm(AQI ~ Pressure + Temperature + Humidity + Traffic )
summary(full_model)
# Test all possible subsets
output      <- ols_step_all_possible(full_model)
# Print results from all possible subsets
output
# Select the best model
ols_step_best_subset(full_model)
ols_step_backward_aic(full_model, details=F)
ols_step_forward_aic(full_model, details=F)
# This is the best model
reg <- lm(AQI ~ Temperature + Traffic )
summary(reg)
Pressure    <- c(999.9,  999.4,  999.1,  999.6,  998.5,
1000.8, 1002.0,  999.4, 1002.7, 1003.2,
996.6, 1003.0, 1004.3, 1000.4,  998.3)
Temperature <- c(20.2, 21.1, 19.3, 17.5, 16.9, 22.5, 13.6,
21.2, 23.5, 18.6, 25.0, 23.6, 17.0, 27.2, 14.1)
Humidity    <- c(44, 56, 20, 31, 60, 48, 76, 65, 60,
74, 68, 69, 50, 36, 63)
Traffic     <- c(357, 256, 270, 541, 254, 337, 411, 280,
289,  88, 275, 358, 380, 268, 523)
AQI         <- c(377, 307, 280, 388, 268, 347, 308, 247,
289, 200, 329, 385, 337, 336, 384)
# Make data frame
AQI_data  <- data.frame(cbind(AQI,Pressure,Temperature,Humidity,Traffic))
str(AQI_data)
# Plot scatter plots
ggpairs(AQI_data,columns=1:5)
# no clear multicollinearity
# Randomness test
runs.test(AQI_data$AQI)
# use dixon.test() to check outliers
dixon.test(AQI_data$AQI)
# no outliers
# Build the full model
full_model <- lm(AQI ~ Pressure + Temperature + Humidity + Traffic )
summary(full_model)
# Test all possible subsets
output      <- ols_step_all_possible(full_model)
# Print results from all possible subsets
output
# Select the best model
ols_step_best_subset(full_model)
ols_step_backward_aic(full_model, details=F)
ols_step_forward_aic(full_model, details=F)
# This is the best model
reg <- lm(AQI ~ Temperature + Traffic )
summary(reg)
# New point
new_points <- data.frame(Pressure = c(1003.0,1001.0 ), Temperature = c(25.0,15.0 ),
Humidity = c(75, 55), Traffic = c(450,300 ) )
# Make prediction for the mean or individual response
predict(reg, newdata = new_points, interval="prediction", level=0.95)
predict(reg, newdata = new_points, interval="confidence", level=0.95)
# Build the full model
full_model <- lm(AQI ~ Pressure + Temperature + Humidity + Traffic )
summary(full_model)
# This is the best model
reg <- lm(AQI ~ Temperature + Traffic )
summary(reg)
predict(reg, newdata = new_points, interval="confidence", level=0.95)
# This is the best model
reg <- lm(AQI ~ Temperature + Traffic )
summary(reg)
# Read data
Keeling_Data     <- read.csv(file = "co2_monthly_mlo_1990_2024.csv", header = T)
# Verify, 2024-02, 2024-03, 2024-04
predicted_co2 <- c(423.7210, 424.3975, 425.9746)
obs_co2       <- c(424.62, 425.38, 426.57)
(predicted_co2-obs_co2)/obs_co2*100
P1 <- c(21, 14, 26, 16, 27,
30, 19, 30, 29, 31,
27, 27, 37, 33, 38 )
P2 <- c(43, 43, 53, 55, 53,
48, 49, 54, 51, 52,
55, 43, 58, 55, 52 )
P1 + P2
shapiro.test(P1)
shapiro.test(P2)
shapiro.test(P1+P2)
mean(P1+P2)
sd(P1+P2)
boxplot(P1+P2)
summary(P1+P2)
hist(P1+P2)
hist(P1)
hist(P2)
boxplot(P1+P2)
shapiro.test(P1)
shapiro.test(P2)
shapiro.test(P1+P2)
hist(P1+P2)
453/8*12
mean1 <- 2.6
sd1   <- 1.9
n1    <- 37
mean2 <- 1.0
sd2   <- 1.0
n2    <- 30
diff <- mean1 - mean2
diff_var <- ((n1-1)*sd1**2 + (n2-1)*sd2**2)/(n1+n2-2)*sqrt(1/n1 + 1/n2)
t_statistic <- diff / diff_var
t_statistic
pt(t_statistic)
mean1 <- 2.6
sd1   <- 1.9
n1    <- 37
mean2 <- 1.0
sd2   <- 1.0
n2    <- 30
diff <- mean1 - mean2
diff_var <- ((n1-1)*sd1**2 + (n2-1)*sd2**2)/(n1+n2-2)*sqrt(1/n1 + 1/n2)
t_statistic <- diff / diff_var
P_value  <- (1-pt(abs(t_statistic), df=n1+n2-2))*2
print(P_value)
n2    <- 27
mean1 <- 3.4
sd1   <- 1.9
n1    <- 37
mean2 <- 4.6
sd2   <- 0.9
n2    <- 27
diff <- mean1 - mean2
diff_var <- ((n1-1)*sd1**2 + (n2-1)*sd2**2)/(n1+n2-2)*sqrt(1/n1 + 1/n2)
t_statistic <- diff / diff_var
# Two-sided
P_value  <- (1-pt(abs(t_statistic), df=n1+n2-2))*2
# One-sided
print(P_value)
library(BSDA)
library(ggplot2)
library(FSA)
library(tidyr)
library(dplyr)
# Make up samples
Treat     <- c(3, 5, 1, 4, 3, 5)
Control   <- c(4, 8, 6, 2, 1, 9)
# Perform the Mann Whitney U test
wilcox.test(Treat, Control, paired=F, alternative="two.sided")
# Make up samples
Treat     <- c(3, 5, 1, 4, 3, 5)
Control   <- c(4, 8, 6, 2, 1, 9)
# Perform the Wilcoxon signed rank test
wilcox.test(Treat, Control, paired=T, alternative="two.sided")
SIGN.test(Treat, Control, alternative = "two.sided", conf.level = 0.95)
# Load data
require(graphics)
# Boxplots
ggplot(airquality, aes(x=Month, y=Ozone, group=Month, fill=Month)) +
geom_boxplot() +
labs(title="Monthly ozone",
x="Month", y="Ozone [ppb]") +
theme_classic()
# Perform the Kruskalâ€“Wallis test
kruskal.test(Ozone ~ Month, data = airquality)
dunnTest(Ozone ~ Month, data=airquality, method="bh")
# Make up some random values
x <- rnorm(20,0,1)
y <- 2*x+rnorm(20,0,0.5)
# Perform the Spearman correlation test
cor.test(x, y, method="spearman", alternative="two.sided", conf.level=0.95)
# Perform the Kendall correlation test
cor.test(x, y, method="kendall", alternative="two.sided", conf.level=0.95)
#------------------------------------
# EX. 1
# Soil organic matter from fileds A-H
SOM_A <- c(2.0, 2.8, 3.3, 3.2, 4.4, 3.6, 1.9, 3.3, 2.8, 1.1)
SOM_B <- c(3.5, 2.8, 3.2, 3.5, 2.3, 2.4, 2.0, 1.6)
SOM_C <- c(3.3, 3.6, 2.6, 3.1, 3.2, 3.3, 2.9, 3.4, 3.2, 3.2)
SOM_D <- c(3.2, 3.3, 3.2, 2.9, 3.3, 2.5, 2.6, 2.8)
SOM_E <- c(2.6, 2.6, 2.9, 2.0, 2.0, 2.1)
SOM_F <- c(3.1, 2.9, 3.1, 2.5)
SOM_G <- c(2.6, 2.2, 2.2, 2.5, 1.2, 1.2)
SOM_H <- c(2.5, 2.4, 3.0, 1.5)
# Make a dataframe
SOM_data  <- data.frame(SOM=c(SOM_A, SOM_B, SOM_C, SOM_D,
SOM_E, SOM_F, SOM_G, SOM_H),
Field=c(rep("Field A", length(SOM_A)),
rep("Field B", length(SOM_B)),
rep("Field C", length(SOM_C)),
rep("Field D", length(SOM_D)),
rep("Field E", length(SOM_E)),
rep("Field F", length(SOM_F)),
rep("Field G", length(SOM_G)),
rep("Field H", length(SOM_H)) ) )
# Plot boxplots
SOM_data %>%
ggplot(aes(x=Field, y=SOM, group=Field, fill=Field)) +
geom_boxplot() +
labs(title="Soil organic matter ",
x="Field", y="SOM [%]") +
theme_classic()
# Perform the Kruskalâ€“Wallis test
kruskal.test(SOM ~ Field, data = SOM_data)
# Perform the post-hoc test to do pairwise comparison
dunnTest(SOM ~ Field, data=SOM_data, method="bh")
?dunnTest
# Perform the post-hoc test to do pairwise comparison
dunnTest(SOM ~ Field, data=SOM_data, method="bh")
library(ggplot2)
library(GGally)
library(olsrr)
# Read ozone and meteorological data
Ozone_data <- read.csv(file = "ozone_data.csv", header=T)
# Check the data
str(Ozone_data)
# Plot scatter plots
ggpairs(Ozone_data, columns=1:5)
#----------------------------------------------------------------------
# Fit the full model, where all independent variables are included
full_model  <- lm(Ozone ~ Solar.Rad + Wind.Speed + Temperature + Pressure, data = Ozone_data)
summary(full_model)
# Test all possible subsets
output      <- ols_step_all_possible(full_model)
# Print results from all possible subsets
output
# Plot results from all possible subsets
plot(output)
#----------------------------------------------------------------------
ols_step_best_subset(full_model)
ols_step_backward_aic(full_model, details=T)
ols_step_forward_aic(full_model, details=F)
ols_step_both_aic(full_model, details=F)
ols_step_backward_aic(full_model, details=F)
ols_step_forward_aic(full_model, details=F)
ols_step_both_aic(full_model, details=F)
#----------------------------------------------------------------------
# Best model
reg <- lm(Ozone ~ Solar.Rad + Wind.Speed + Temperature , data = Ozone_data)
summary(reg)
par(mfrow = c(2, 2))
plot(reg)
par(mfrow = c(1, 1))
# Make confidence band
predict(reg, interval="confidence", level=0.95)
# Make prediction band
predict(reg, interval="prediction", level=0.95)
#----------------------------------------------------------------------
# EX 1
# 1.1 Load data
library(MASS)
data(cpus)
# 1.2 Partitioning training (85%) and validation (15%) subsets
fraction        <- 0.85
sample_index    <- sample(nrow(cpus),nrow(cpus)*fraction)
cpus_training   <- cpus[sample_index,]
cpus_validation <- cpus[-sample_index,]
# 1.3 Plot scatter plots
ggpairs(cpus_training, columns=2:9)
# 1.4 Full model
full_model <- lm(perf  ~ syct   + mmin   + mmax  + cach + chmin + chmax, data = cpus_training)
summary(full_model)
# Variable selection
# 1.5 Use the all possible subsets approach to find the best model
ols_step_all_possible(full_model)
# 1.6 Use the all best subsets approach to find the best model
ols_step_best_subset(full_model)
# 1.7 Use backward elimination approach to find the best model.
ols_step_backward_aic(full_model)
# 1.8 Use forward selection approach to find the best model.
ols_step_forward_aic(full_model)
# 1.9 Use stepwise regression approach to find the best model.
ols_step_both_aic(full_model)
# 1.10 Best model
reg <- lm(perf  ~ syct   + mmin   + mmax  + cach + chmax, data = cpus_training)
summary(reg)
# Check assumptions
par(mfrow = c(2, 2))
plot(reg)
par(mfrow = c(1, 1))
# 1.11 Predicted individual CPU performance of the validation subset
pred <- predict(reg, cpus_validation,interval="prediction", level=0.95)
# Compare
plot(pred[,1],cpus_validation$perf, xlab="Predicted CPU performance",
ylab="Actual CPU performance")
# Get Pearson correlation coefficient and relative mean bias
cor(pred[,1],cpus_validation$perf)
# Get relative mean bias
mean_bias <- mean(pred[,1]) - mean(cpus_validation$perf)
mean_bias/mean(cpus_validation$perf)*100
# 1.12 Simulations
N_simulations     <- 50
correlation_all   <- c()
relative_bias_all <- c()
# Loop each simulation
for(i in 1:N_simulations){
# Create new subsets each time
# Partitioning training (85%) and validation (15%) subsets
fraction        <- 0.85
sample_index    <- sample(nrow(cpus),nrow(cpus)*fraction)
cpus_training   <- cpus[sample_index,]
cpus_validation <- cpus[-sample_index,]
# Using the same best model
reg <- lm(perf  ~ syct   + mmin   + mmax  + cach + chmax, data = cpus_training)
pred <- predict(reg, cpus_validation, interval="prediction", level=0.95)
# Get Pearson correlation coefficient and relative mean bias
cor_temp <- cor(pred[,1],cpus_validation$perf)
# Get relative mean bias
mean_bias          <- mean(pred[,1]) - mean(cpus_validation$perf)
relative_bias_temp <- mean_bias/mean(cpus_validation$perf)*100
# Store
correlation_all   <- c(correlation_all, cor_temp)
relative_bias_all <- c(relative_bias_all, relative_bias_temp)
}
# Mean Pearson correlation coefficient
hist(correlation_all)
abline(v=mean(correlation_all), col="red")
mean(correlation_all) # ~ 0.90, not bad
# Mean relative mean bias
hist(relative_bias_all)
abline(v=mean(relative_bias_all), col="blue")
mean(relative_bias_all) # 1-2%, very good!
setwd("D://repo/ese335")
rmarkdown::render_site()
rmarkdown::render_site()
