# Test
if(opposite){
# Test for the low values
print("Test of low values")
w    <- data_new[k]-(1+a)*data_new[k+1]+a*data_new[p]
if( w <0 ){
print(paste("The lowest",k,"values are outlier:"))
print(data_new[1:k])
}
}else{
# Test for the high values
print("Test of high values")
w    <- -1*data_new[n+1-k]+(1+a)*data_new[n-k]+a*data_new[n+1-p]
if( w < 0 ){
print(paste("The highest",k,"values are outlier:"))
print(data_new[(n+1-1):(n+1-k)])
}
}
}
sample <- c(runif(250,0,1), -90, -91, -100)
walsh.test(sample, k = 3, alpha = 0.05,opposite=T)
21*21
round(rnomr(20,1,0.5))
round(rnorm(20,1,0.5),0.2)
round(rnorm(20,1,0.5),2)
round(rnorm(20,1.2,0.7),2)
round(rnorm(20,1.5,0.7),2)
round(rnorm(20,5,1),2)
round(rnorm(20,5,3),2)
round(rnorm(20,5,3),2)
round(rnorm(20,5,3),2)
round(rnorm(20,7,4),2)
shapiro.test(sample1)
sample1 <- c(8.52, 5.91,  1.97, 5.02,  0.92,  20.12, 4.34,  4.35,  7.39,  4.74, 45,17, 3.65,  0.76,
6.70,  1.37,  3.61,  4.44,  10.29, 2.15, 10.07)
shapiro.test(sample1)
boxplot(sample1)
rosnerTest(sample1)
rosnerTest(sample1,k=2)
dixon.test(sample1)
sample1 <- c(8.52, 5.91,  1.97, 5.02,  0.92,  20.12, 4.34,  4.35,  7.39,  4.74, 3.65,  0.76,
6.70,  1.37,  3.61,  4.44,  10.29, 2.15, 10.07)
shapiro.test(sample1)
boxplot(sample1)
sample1 <- c(8.52, 5.91,  1.97, 5.02,  0.92,  20.12, 4.34,  4.35,  7.39,  4.74, 45.17, 3.65,  0.76,
6.70,  1.37,  3.61,  4.44,  10.29, 2.15, 10.07)
shapiro.test(sample1)
boxplot(sample1)
sample1 <- c(8.52, 5.91,  1.97, 5.02,  0.92,  20.12, 4.34,  4.35,  7.39,  4.74, 5.17, 3.65,  0.76,
6.70,  1.37,  3.61,  4.44,  10.29, 2.15, 10.07)
shapiro.test(sample1)
boxplot(sample1)
sample1 <- c(8.52, 5.91,  1.97, 5.02,  0.92, 4.34,  4.35,  7.39,  4.74, 5.17, 3.65,  0.76,
6.70,  1.37,  3.61,  4.44,  10.29, 2.15, 10.07)
shapiro.test(sample1)
rosnerTest(sample1,k=1)
dixon.test(sample1)
#
sample1 <- c(8.52, 5.91,  1.97, 5.02,  0.92,  20.12, 4.34,  4.35,  7.39,  4.74, 5.17, 3.65,  0.76,
6.70,  1.37,  3.61,  4.44,  15.29, 2.15, 10.07)
shapiro.test(sample1)
boxplot(sample1)
rosnerTest(sample1,k=1)
dixon.test(sample1)
rosnerTest(sample1,k=2)
dixon.test(sample1)
skewness(sample1)
shapiro.test(sample2)
sample2<- c(6.38, 10.59, 11.63, 8.62, 13.60,  6.60,  5.10, 12.31, 0.62,  9.00,  0.42,  4.81,  8.25)
shapiro.test(sample2)
boxplot(sample2)
rosnerTest(sample2,k=1)
skewness(sample2)
dixon.test(sample2)
skewness(sample1)
skewness(sample2)
sample2<- c(6.38, 10.59, 11.63, 8.62, 13.60,  6.60,  15.10, 12.31, 0.62,  9.00,  0.42,  4.81,  8.25)
shapiro.test(sample2)
boxplot(sample2)
rosnerTest(sample2,k=1)
skewness(sample2)
dixon.test(sample2)
sample2<- c(6.38, 10.59, 11.63, 18.62, 13.60,  6.60,  15.10, 12.31, 9.62,  9.00,  6.42,  4.81,  8.25)
shapiro.test(sample2)
boxplot(sample2)
rosnerTest(sample2,k=1)
skewness(sample2)
dixon.test(sample2)
t.test(sample1, sample2, var.equal = F)
rosnerTest(sample1,k=2)
rosnerTest(sample1,k=3)
sample1_new <- c(8.52, 5.91,  1.97, 5.02,  0.92,  4.34,  4.35,  7.39,  4.74, 5.17, 3.65,  0.76,
6.70,  1.37,  3.61,  4.44,  2.15, 10.07)
t.test(sample1_new, sample2, var.equal = F)
t.test(sample1, sample2, var.equal = F)
sample1 <- c(8.52, 5.91,  1.97, 5.02,  9.92,  20.12, 4.34,  4.35,  7.39,  4.74, 5.17, 3.65,  0.76,
6.70,  8.37,  3.61,  4.44,  15.29, 7.15, 10.07)
shapiro.test(sample1)
boxplot(sample1)
rosnerTest(sample1,k=2)
skewness(sample1)
dixon.test(sample1)
t.test(sample1, sample2, var.equal = F)
sample1 <- c(8.52, 5.91,  4.97, 5.02,  9.92,  20.12, 4.34,  4.35,  7.39,  4.74, 5.17, 10.65,  9.76,
6.70,  8.37,  3.61,  4.44,  15.29, 7.15, 10.07)
shapiro.test(sample1)
boxplot(sample1)
rosnerTest(sample1,k=2)
skewness(sample1)
dixon.test(sample1)
t.test(sample1, sample2, var.equal = F)
sample1_new <- c(8.52, 5.91,  1.97, 5.02,  0.92,  4.34,  4.35,  7.39,  4.74, 5.17, 3.65,  0.76,
6.70,  8.37,  3.61,  4.44,  15.29, 7.15, 10.07)
t.test(sample1_new, sample2, var.equal = F)
sample1_new <- c(8.52, 5.91,  1.97, 5.02,  0.92,  4.34,  4.35,  7.39,  4.74, 5.17, 3.65,  0.76,
6.70,  8.37,  3.61,  4.44,  15.29, 7.15, 10.07)
t.test(sample1_new, sample2, var.equal = F)
skewness(sample2)
skewness(sample1)
#
sample1 <- c(8.52, 5.91,  4.97, 5.02,  9.92,  20.12, 4.34,  4.35,  7.39,  4.74, 5.17, 10.65,  9.76,
6.70,  8.37,  3.61,  4.44,  15.29, 7.15, 10.07)
shapiro.test(sample1)
boxplot(sample1)
rosnerTest(sample1,k=2)
skewness(sample1)
dixon.test(sample1)
sample2<- c(6.38, 10.59, 11.63, 18.62, 13.60,  6.60,  15.10, 12.31, 9.62,  9.00,  6.42,  4.81,  8.25)
shapiro.test(sample2)
boxplot(sample2)
rosnerTest(sample2,k=1)
skewness(sample2)
dixon.test(sample2)
shapiro.test(sample1)
boxplot(sample1)
rosnerTest(sample1,k=1)
skewness(sample1)
dixon.test(sample1)
t.test(sample1_new, sample2, var.equal = F)
shapiro.test(sample1_new)
setwd("D://ese335")
rmarkdown::render_site()
rmarkdown::render_site()
rmarkdown::render_site()
library(ggplot2)
# Section example
Unseeded <- c(1202.6, 830.1, 372.4, 345.5, 321.2, 244.3, 163.0, 147.8, 95.0, 87.0, 81.2, 68.5, 47.3,
41.1, 36.6, 29.0, 28.6, 26.3, 26.0, 24.4, 21.4, 17.3, 11.5, 4.9, 4.9, 1.0)
Seeded   <- c(2745.6, 1697.1, 1656.4, 978.0, 703.4, 489.1, 430.0, 334.1, 302.8, 274.7, 274.7, 255.0,
242.5, 200.7, 198.6, 129.6, 119.0, 118.3, 115.3, 92.4, 40.6, 32.7, 31.4, 17.5, 7.7, 4.1)
# Plot boxplots
# Make data frame
Rainfall_data <- data.frame(Rainfall = c(Unseeded, Seeded),
Seeded= c(rep("No",length(Unseeded)),rep("Yes",length(Seeded))))
# Compare boxplots
Rainfall_data %>%
ggplot(aes(x=as.character(Seeded), y=Rainfall)) +
geom_boxplot(fill="steelblue") +
labs(title="Rainfall Distribution", x="Seeded", y="Rainfall [acre-feet]")
# Samples
Unseeded <- c(1202.6, 830.1, 372.4, 345.5, 321.2, 244.3, 163.0, 147.8, 95.0, 87.0, 81.2, 68.5, 47.3,
41.1, 36.6, 29.0, 28.6, 26.3, 26.0, 24.4, 21.4, 17.3, 11.5, 4.9, 4.9, 1.0)
shapiro.test(Unseeded)
Seeded   <- c(2745.6, 1697.1, 1656.4, 978.0, 703.4, 489.1, 430.0, 334.1, 302.8, 274.7, 274.7, 255.0,
242.5, 200.7, 198.6, 129.6, 119.0, 118.3, 115.3, 92.4, 40.6, 32.7, 31.4, 17.5, 7.7, 4.1)
shapiro.test(Seeded)
# Make data frame
Rainfall_data <- data.frame(Rainfall = c(Unseeded, Seeded),
Seeded= c(rep("No",length(Unseeded)),rep("Yes",length(Seeded))))
# Compare boxplots
Rainfall_data %>%
ggplot(aes(x=as.character(Seeded), y=Rainfall)) +
geom_boxplot(fill="steelblue") +
labs(title="Rainfall Distribution", x="Seeded", y="Rainfall [acre-feet]")
# Shenzhen
SZ_PM2.5  <- c(25.6, 23.7, 21.9, 26.0, 24.5, 22.4, 26.7, 24.6, 22.7, 23.8)
# Guangzhou
GZ_PM2.5  <- c(27.1, 24.2, 27.9, 33.3, 26.4, 28.7, 25.6, 23.2, 24.0, 27.1, 26.2, 24.4)
# Sample difference
mean(SZ_PM2.5) - mean(GZ_PM2.5)
# Get sample size, degrees of freedom, and sd
n1        <- length(SZ_PM2.5)
df1       <- n1 - 1
sd1       <- sd(SZ_PM2.5)
n2        <- length(GZ_PM2.5)
df2       <- n2 - 1
sd2       <- sd(GZ_PM2.5)
# SE of the difference
SE        <- sqrt( sd1^2/n1 + sd2^2/n2 )
SE
# Shenzhen
SZ_PM2.5  <- c(25.6, 23.7, 21.9, 26.0, 24.5, 22.4, 26.7, 24.6, 22.7, 23.8)
# Guangzhou
GZ_PM2.5  <- c(27.1, 24.2, 27.9, 33.3, 26.4, 28.7, 25.6, 23.2, 24.0, 27.1, 26.2, 24.4)
# Sample difference
mean(SZ_PM2.5) - mean(GZ_PM2.5)
# Get sample size, degrees of freedom, and sd
n1        <- length(SZ_PM2.5)
df1       <- n1 - 1
sd1       <- sd(SZ_PM2.5)
n2        <- length(GZ_PM2.5)
df2       <- n2 - 1
sd2       <- sd(GZ_PM2.5)
# SE of the difference
SE_W      <- sqrt( sd1^2/n1 + sd2^2/n2 )
# d.f.W
df        <- SE_W^4/( (sd1/sqrt(n1))^4/(n1-1) + (sd2/sqrt(n2))^4/(n2-1) )
# Get t-ratio
t         <- (mean(SZ_PM2.5) - mean(GZ_PM2.5))/SE_W
# Find the two-side p-value
# The pt function gives the Cumulative Distribution Function (CDF)
# of the Student's t distribution in R, which is the probability that
# the variable takes a value lower or equal to a threshold (here |t|).
P_value  <- (1-pt(abs(t), df=df))*2
print(P_value)
# Get t-ratio
rmarkdown::render_site()
rmarkdown::render_site()
# Total simulations
Total_simulations <- 1000
# Population 1, form a log normal distribution
pop1 <- rlnorm(4000, 1, 0.2)
shapiro.test(pop1)
# Population 2, form a log normal distribution
pop2 <- rlnorm(4000, 2, 2)
shapiro.test(pop2)
skewness(pop2)
shapiro.test(pop2)
# Total simulations
Total_simulations <- 1000
# Population 1, form a log normal distribution
pop1 <- rlnorm(4000, 1, 0.2)
shapiro.test(pop1)
skewness(pop1)
# Population 2, form a log normal distribution
pop2 <- rlnorm(4000, 2, 2)
shapiro.test(pop2)
skewness(pop2)
# Sample size
N1 <- 200
N2 <- 200
# List to store p-value
p_value <- c()
# Run simulation
for(i in 1:Total_simulations){
# Sample 1
s1 <- sample(pop1,N1)
# Sample 2
s2 <- sample(pop2,N2)
# Do t-test, despite of the normality
p_value <- c(p_value, t.test(s1,s2,var.equal=T)$p.value)
}
# Check the robustness
length(which(p_value<0.05))/Total_simulations
p_value
length(which(p_value<0.05))
# Check the robustness
length(which(p_value<0.05))/Total_simulations
# Total simulations
Total_simulations <- 1000
# Population 1, form a log normal distribution
pop1 <- rlnorm(4000, 1, 0.2)
shapiro.test(pop1)
skewness(pop1)
# Population 2, form a log normal distribution
pop2 <- rlnorm(4000, 2, 0.5)
shapiro.test(pop2)
skewness(pop2)
# Total simulations
Total_simulations <- 1000
# Population 1, form a log normal distribution
pop1 <- rlnorm(4000, 1, 0.2)
shapiro.test(pop1)
skewness(pop1)
# Population 2, form a log normal distribution
pop2 <- rlnorm(4000, 2, 0.5)
shapiro.test(pop2)
skewness(pop2)
# Sample size
N1 <- 20
N2 <- 40
# List to store p-value
p_value <- c()
# Run simulation
for(i in 1:Total_simulations){
# Sample 1
s1 <- sample(pop1,N1)
# Sample 2
s2 <- sample(pop2,N2)
# Do t-test, despite of the normality
p_value <- c(p_value, t.test(s1,s2,var.equal=T)$p.value)
}
# Check the robustness
length(which(p_value<0.05))/Total_simulations
# Sample size
N1 <- 20
N2 <- 20
# List to store p-value
p_value <- c()
# Run simulation
for(i in 1:Total_simulations){
# Sample 1
s1 <- sample(pop1,N1)
# Sample 2
s2 <- sample(pop2,N2)
# Do t-test, despite of the normality
p_value <- c(p_value, t.test(s1,s2,var.equal=T)$p.value)
}
# Check the robustness
length(which(p_value<0.05))/Total_simulations
# Total simulations
Total_simulations <- 1000
# Population 1, form a log normal distribution
pop1 <- rlnorm(4000, 1, 0.2)
shapiro.test(pop1)
skewness(pop1)
# Population 2, form a log normal distribution
pop2 <- rlnorm(4000, 2, 1.0)
shapiro.test(pop2)
skewness(pop2)
# Sample size
N1 <- 20
N2 <- 20
# List to store p-value
p_value <- c()
# Run simulation
for(i in 1:Total_simulations){
# Sample 1
s1 <- sample(pop1,N1)
# Sample 2
s2 <- sample(pop2,N2)
# Do t-test, despite of the normality
p_value <- c(p_value, t.test(s1,s2,var.equal=T)$p.value)
}
# Check the robustness
length(which(p_value<0.05))/Total_simulations
# Total simulations
Total_simulations <- 1000
# Population 1, form a log normal distribution
pop1 <- rlnorm(4000, 1, 0.2)
shapiro.test(pop1)
skewness(pop1)
# Population 2, form a log normal distribution
pop2 <- rlnorm(4000, 2, 5.0)
shapiro.test(pop2)
skewness(pop2)
# Sample size
N1 <- 200
N2 <- 200
# List to store p-value
p_value <- c()
# Run simulation
for(i in 1:Total_simulations){
# Sample 1
s1 <- sample(pop1,N1)
# Sample 2
s2 <- sample(pop2,N2)
# Do t-test, despite of the normality
p_value <- c(p_value, t.test(s1,s2,var.equal=T)$p.value)
}
# Check the robustness
length(which(p_value<0.05))/Total_simulations
skewness(pop2)
skewness(pop1)
# Sample size
N1 <- 200
N2 <- 200
# List to store p-value
p_value <- c()
# Run simulation
for(i in 1:Total_simulations){
# Sample 1
s1 <- sample(pop1,N1)
# Sample 2
s2 <- sample(pop2,N2)
# Do t-test, despite of the normality
p_value <- c(p_value, t.test(s1,s2,var.equal=T)$p.value)
}
# Check the robustness
length(which(p_value<0.05))/Total_simulations
# Total simulations
Total_simulations <- 1000
# Population 1, form a log normal distribution
pop1 <- rlnorm(4000, 1, 0.2)
shapiro.test(pop1)
skewness(pop1)
# Population 2, form a log normal distribution
pop2 <- rlnorm(4000, 2, 5.0)
shapiro.test(pop2)
skewness(pop2)
# Sample size
N1 <- 20
N2 <- 30
# List to store p-value
p_value <- c()
# Run simulation
for(i in 1:Total_simulations){
# Sample 1
s1 <- sample(pop1,N1)
# Sample 2
s2 <- sample(pop2,N2)
# Do t-test, despite of the normality
p_value <- c(p_value, t.test(s1,s2,var.equal=T)$p.value)
}
# Check the robustness
length(which(p_value<0.05))/Total_simulations
# Create a sample
Sample1 <- c(12, 16, 16, 15, 14, 18, 19, 21, 13, 13, 12, 16, 16, 15, 14)
# Perform Runs test
runs.test(Sample1)
Sample1 <- c(12, 16, 16, 15, 14, 18, 19, 21, 13, 13, 12, 16, 16, 15, 14)
Sample2 <- c(Sample1, Sample1*2)
Sample2
# Perform Runs test
runs.test(Sample2)
# Shenzhen
SZ_PM2.5  <- c(25.6, 23.7, 21.9, 26.0, 24.5, 22.4, 26.7, 24.6, 22.7, 23.8)
# Guangzhou
GZ_PM2.5  <- c(27.1, 24.2, 27.9, 33.3, 26.4, 28.7, 25.6, 23.2, 24.0, 27.1, 26.2, 24.4)
# Call t.test function
# Since H1 states a different PM2.5 value in Shenzhen,
# we need to compute the two-sided p-value
t.test(SZ_PM2.5, GZ_PM2.5, alternative="two.sided", var.equal=F)
# Call t.test function
# Since H1 states a different PM2.5 value in Shenzhen,
# we need to compute the two-sided p-value
t.test(SZ_PM2.5, GZ_PM2.5, alternative="two.sided")
# Sample
Sample1 <- c(0.2, 0.8, -2.0, -7.0, -0.8, 0.8, 0.9, -1.1, -1.3, -0.3, 1.6, 8.3)
# Boxplot
boxplot(Sample1)
# Sample
Sample1 <- c(0.2, 0.8, -2.0, -7.0, -0.8, 0.8, 0.9, -1.1, -1.3, -0.3, 1.6, 8.3)
# Boxplot
boxplot(Sample1)
# Test for the highest value with Grubbs' test
grubbs.test(Sample1)
# Test for the lowest value with Grubbs' test
grubbs.test(Sample1,opposite = T)
# Test for the highest value with Dixon's test
dixon.test(Sample1)
dixon.test(Sample1, opposite = T)
# New Sample
Sample2 <- c(-0.4, 0.6, -0.6, 0.2, -7.0, -0.8, 0.6, -0.3, -1.3, 1.4,
-0.8, -1.2, 1.4, -0.5, -0.5, -1.2, -0.8, -2.5, 0.1,
-1.7, 0.6, 0.3, -2.3, 0.6, -0.1, 0.3, 8.3)
# Boxplot
boxplot(Sample2)
# Test for the highest value with Rosner's test
# number of suspected outliers is 2 (k=2)
rosnerTest(Sample2, k=2)
# Walsh's Outlier Test
# By Lei Zhu, 03/29/2021
# Details see:
# http://www.statistics4u.com/fundstat_eng/ee_walsh_outliertest.html
walsh.test <- function(data, k, alpha, opposite=F){
# Sample size
n    <- length(data)
# sorted data
data_new <- sort(data)
# Get parameters
c    <- ceiling(sqrt(2*n))
p    <- k + c
b2   <- 1/alpha
a    <- (1+sqrt(b2)*sqrt((c-b2)/(c-1)))/(c-b2-1)
# Test
if(opposite){
# Test for the low values
print("Walsh's test of low values")
w    <- data_new[k]-(1+a)*data_new[k+1]+a*data_new[p]
if( w <0 ){
print(paste("The lowest",k,"values are outlier:"))
print(data_new[1:k])
}
}else{
# Test for the high values
print("Walsh's test of high values")
w    <- -1*data_new[n+1-k]+(1+a)*data_new[n-k]+a*data_new[n+1-p]
if( w < 0 ){
print(paste("The highest",k,"values are outlier:"))
print(data_new[(n+1-1):(n+1-k)])
}
}
}
# Make up a sample
sample <- c(runif(250,0,1), -90, -91, -100, 90, 91, 100)
# Perform Walsh's test
# Test for the 3 highest values
walsh.test(sample, k=3, alpha = 0.05)
# Make up a sample
sample <- c(runif(250,0,1), -90, -91, -100, 90, 91, 100)
boxplot(sample)
Sample1 <- c(8.52, 5.91,  4.97, 5.02,  9.92,  20.12, 4.34,  4.35,
7.39,  4.74, 5.17, 10.65,  9.76,
6.70,  8.37,  3.61,  4.44,  15.29, 7.15, 10.07)
Sample2 <- c(6.38, 10.59, 11.63, 18.62, 13.60,  6.60,  15.10,
12.31, 9.62,  9.00,  6.42,  4.81,  8.25)
boxplot(Sampel1)
boxplot(Sample1)
boxplot(Sample2)
rosnerTest(Sample1,1)
dixon.test(Sample1)
# t-test w. the outlier
t.test(Sample1, Sample2, alternative ="two.sided" ,var.equal = F)
# t-test w./o the outlier
Sample1_new <- c(8.52, 5.91,  4.97, 5.02,  9.92,  4.34,  4.35,
7.39,  4.74, 5.17, 10.65,  9.76,
6.70,  8.37,  3.61,  4.44,  15.29, 7.15, 10.07)
t.test(Sample1_new, Sample2, alternative ="two.sided" ,var.equal = F)
# t-test w. the outlier
t.test(Sample1, Sample2, alternative ="two.sided" ,var.equal = F)
t.test(Sample1_new, Sample2, alternative ="two.sided" ,var.equal = F)
