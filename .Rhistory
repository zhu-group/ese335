# Section 19
# COVID-19 daily cases
# Load libraries
library(dplyr)
library(lubridate)
library(forecast)
# Read in the COVID-19 data
COVID_data <- read.csv(file = "COVID_2020_data.csv", header = T)
# Read in the COVID-19 data
COVID_data <- read.csv(file = "COVID_2020_data.csv", header = T)
# Check the variable names
head(COVID_data)
# Convert the data.frame to a tibble
COVID_tbl <- as_tibble(COVID_data)
# Show data
COVID_tbl
dateRep
# Get global daily new cases
COVID_tbl <- COVID_tbl %>%
mutate(dateRep = as.Date(dateRep, format='%d/%m/%Y')) %>%
group_by(dateRep) %>%
summarize(global_cases = sum(cases))
# Show data
COVID_tbl
# Quick plot
plot(COVID_tbl$dateRep,COVID_tbl$global_cases,
type="l", xlab="Date", ylab="Global cases")
# Filter the data, only use data from April 01
COVID_tbl <- COVID_tbl %>%
filter(dateRep >= as.Date("2020-04-01"))
# Show data
COVID_tbl
# Quick plot
plot(COVID_tbl$dateRep,COVID_tbl$global_cases,
type="l", xlab="Date", ylab="Global cases")
# Start date of the time series, read from the .csv file
Date_start <- as.Date("2020-04-01")
# End date of the time series, read from the .csv file
Date_end   <- as.Date("2020-11-09")
# Get the Julian Day of the start and end date
JD_start   <- yday(Date_start)
JD_end     <- yday(Date_end)
N_days     <- JD_end - JD_start + 1
# Convert the vector data to a time series
global_cases_ts <- ts(COVID_tbl$global_cases[1:N_days], start=c(2020,JD_start), frequency=365)
# The indicator of the time series
inds            <- seq(Date_start, Date_end, by="day")
# Check structure
str(global_cases_ts)
# Plot time series
plot(inds, global_cases_ts, type="l")
# Data transform with log
global_cases_ts_log <- log(global_cases_ts)
# Plot time series
plot(inds, global_cases_ts_log, type="l")
# Check acf and pacf
acf(global_cases_ts_log)
pacf(global_cases_ts_log)
# Take the diff, d=1
global_cases_ts_log_d1 <- diff(global_cases_ts_log)
# Plot time series
plot(global_cases_ts_log_d1,type="l")
# Check acf and pacf
acf(global_cases_ts_log_d1)
pacf(global_cases_ts_log_d1)
# Automated forecasting using an ARIMA model
model <- auto.arima(global_cases_ts_log)
# Show details of the ARIMA model
model
# Number of days to predict
days_forecast  <- 30
# Number of include in the plot
days_in_plot   <- 30
# Make predictions using the forecast() function
forecast_30days <- forecast(model, days_forecast)
# Plot
plot(forecast_30days, include=days_in_plot,
xlab="Time", ylab="log(global cases)", type="o", lwd=2)
# Number of days to predict
days_forecast  <- 100
# Number of include in the plot
days_in_plot   <- 30
# Make predictions using the forecast() function
forecast_30days <- forecast(model, days_forecast)
# Plot
plot(forecast_30days, include=days_in_plot,
xlab="Time", ylab="log(global cases)", type="o", lwd=2)
# Get predicted values on Nov 10, 2020
day_forward <- yday(as.Date("2020-11-10")) - yday(Date_end)
exp(forecast_30days$mean[day_forward])
exp(forecast_30days$lower[day_forward,1])
exp(forecast_30days$upper[day_forward,1])
# Get predicted values on Nov 30, 2020
day_forward <- yday(as.Date("2020-11-30")) - yday(Date_end)
exp(forecast_30days$mean[day_forward])
exp(forecast_30days$lower[day_forward,1])
exp(forecast_30days$upper[day_forward,1])
# Get predicted values on Nov 10, 2020
day_forward <- yday(as.Date("2020-11-10")) - yday(Date_end)
exp(forecast_30days$mean[day_forward])
exp(forecast_30days$lower[day_forward,1])
exp(forecast_30days$upper[day_forward,1])
# Get global daily new cases
COVID_tbl2 <- COVID_tbl2 %>%
mutate(dateRep = as.Date(dateRep,format='%d/%m/%Y')) %>%
group_by(dateRep) %>%
summarize(global_cases = sum(cases))
# Read data
COVID_data2 <- read.csv(file = "COVID_2020_data_new.csv", header = T)
COVID_tbl2  <- as_tibble(COVID_data2)
# Get global daily new cases
COVID_tbl2 <- COVID_tbl2 %>%
mutate(dateRep = as.Date(dateRep,format='%d/%m/%Y')) %>%
group_by(dateRep) %>%
summarize(global_cases = sum(cases))
COVID_tbl2
# Real values at Nov 10 and 30
COVID_tbl2[COVID_tbl2$dateRep=="2020-11-10", ]
COVID_tbl2[COVID_tbl2$dateRep=="2020-11-30", ]
# Get predicted values on Nov 10, 2020
day_forward <- yday(as.Date("2020-11-10")) - yday(Date_end)
exp(forecast_30days$mean[day_forward])
exp(forecast_30days$lower[day_forward,1])
exp(forecast_30days$upper[day_forward,1])
# Get predicted values on Nov 30, 2020
day_forward <- yday(as.Date("2020-11-30")) - yday(Date_end)
exp(forecast_30days$mean[day_forward])
exp(forecast_30days$lower[day_forward,1])
exp(forecast_30days$upper[day_forward,1])
sample(seq(1,17),1)
# Read data
COVID_data2 <- read.csv(file = "COVID_2020_data_new.csv", header = T)
COVID_tbl2  <- as_tibble(COVID_data2)
(500063.9-502287)/502287
(500063.9-502287)/502287*100
# Get predicted values on Nov 30, 2020
day_forward <- yday(as.Date("2020-11-30")) - yday(Date_end)
exp(forecast_30days$mean[day_forward])
exp(forecast_30days$lower[day_forward,1])
exp(forecast_30days$upper[day_forward,1])
# Predicted global cases: 613331.2
# True cases: 516616
(613331.2-516616)/516616*100
rgdal
?get_stadiamap
?register_stadiamaps
library(rgdal)
library(ggplot2)
library(plyr)
library(dplyr)
library(ggsn)
library(raster)
library(ggmap)
library(mapproj)
# Site information
Site_name <- c("SUSTech", "Longhua", "Xichong", "Baoan", "Kuiyong")
Site_lon  <- c(114.06667,114.02200,114.56111,113.89606,114.42824)
Site_lat  <- c(22.61667,22.72882,22.48077,22.53965,22.63427)
Site_type <- c("Urban", "Urban", "Background", "Urban", "Rural")
# Make a data frame
Site_data <- data.frame(name=Site_name, lon=Site_lon, lat=Site_lat, type=Site_type)
# Get the lat and lon range
Mapbox    <- make_bbox(lon = Site_data$lon, lat = Site_data$lat, f = .1)
# Pull the base map, ***you may need a VPN to download the base map ***
# The keyword zoom defines the map resolution
Base_map  <- get_stadiamap(Mapbox, zoom = 10, maptype = "stamen_terrain")
ggmap(Base_map)
# Plot
ggmap(Base_map) +
# Add sites
geom_point(data=Site_data, aes(x=lon, y=lat, fill=type, shape=type),
color="white", cex=5.5) + # plot the points
# Change color
scale_fill_manual(values = c("green", "blue", "red"),
labels=c("Background", "Rural","Urban"), name=NULL) +
# Change shape
scale_shape_manual(values = c(21,22,24),
labels=c("Background", "Rural","Urban"), name=NULL) +
# Change labels and title
labs(x="Latitude", y="Longitude", title="Monitoring sites") + # label the axes
# Change theme
theme_bw() +
theme(legend.position="bottom",
legend.key  = element_rect(colour = "white"),
axis.text   = element_text(size = rel(0.75)),
axis.text.x = element_text(angle=45, vjust=0.5))
library(rgdal)
library(ggplot2)
library(plyr)
library(dplyr)
library(ggsn)
library(raster)
library(ggmap)
library(mapproj)
# maptools
# install.packages("maptools", repos = "https://packagemanager.posit.co/cran/2023-10-13")
# ggsn
# devtools::install_github('oswaldosantos/ggsn')
# rgdal
# install.packages("rgdal", repos = "https://packagemanager.posit.co/cran/2023-10-13")
#--------------------------------------------------
# Read Shape files
# Location of the .shp file
Local_path <- "China_map/"
# Read china map, a shape file
China_map <- rgdal::readOGR(paste0(Local_path, "bou2_4p.shp"))
# Check the attributes
class(China_map)
# Show variable names
names(China_map)
# Check the attributes, use the operator @
map_data <- China_map@data
head(map_data)
China_map$NAME
# Convert characters
China_map$NAME <- iconv(China_map$NAME, "GBK")
# Check the attributes, use the operator @
map_data <- China_map@data
head(map_data)
map_data <- China_map@data
head(map_data)
tail(map_data)
# Quick plot use ggplot
ggplot(China_map, aes(x = long, y = lat, group = group)) +
geom_polygon(fill = 'lightblue') +
geom_path(color = "grey40")
setwd("D://repo/ese335")
rmarkdown::render_site()
