rosnerTest(Small_litter, k=2)
rosnerTest(Large_litter, k=2)
grubbs.test(Small_litter)
grubbs.test(Large_litter)
# Large sample size, use t-test
t.test(Small_litter, Large_litter, alternative = "two.sided", paired = F, var.equal = F)
#-----------------------------------------------------------
# EX 3
#-----------------------------------------------------------
Rib_16           <- c(11.10, 11.22, 11.29, 11.49)
Gastralia1       <- c(11.32, 11.40, 11.71)
Gastralia2       <- c(11.60, 11.78, 12.05)
Dorsal_vertebra1 <- c(10.61, 10.88, 11.12, 11.24, 11.43)
Dorsal_vertebra2 <- c(10.92, 11.20, 11.30, 11.62, 11.70)
Femur            <- c(11.70, 11.79, 11.91, 12.15)
Tibia            <- c(11.33, 11.41, 11.62, 12.15, 12.30)
Metatarsal       <- c(11.32, 11.65, 11.96, 12.15)
Phalange         <- c(11.54, 11.89, 12.04)
Proximal_caudal  <- c(10.93, 11.01, 11.08, 11.12, 11.28, 11.37)
Mid_caudal       <- c(11.35, 11.43, 11.50, 11.57, 11.92)
Distal_caudal    <- c(11.95, 12.01, 12.25, 12.30, 12.39)
# Make data frame
oxygen_data <- data.frame( Oxygen_isotopic = c(Rib_16, Gastralia1, Gastralia2, Dorsal_vertebra1,
Dorsal_vertebra2, Femur, Tibia, Metatarsal, Phalange,
Proximal_caudal, Mid_caudal, Distal_caudal),
Bone  = c(rep("Rib_16",length(Rib_16))        , rep("Gastralia1",length(Gastralia1))            ,
rep("Gastralia2",length(Gastralia2)), rep("Dorsal_vertebra1",length(Dorsal_vertebra1)),
rep("Dorsal_vertebra2",length(Dorsal_vertebra2)), rep("Femur",length(Femur))          ,
rep("Tibia",length(Tibia))          , rep("Metatarsal",length(Metatarsal))            ,
rep("Phalange",length(Phalange))    , rep("Proximal_caudal",length(Proximal_caudal))  ,
rep("Mid_caudal",length(Mid_caudal)), rep("Distal_caudal",length(Distal_caudal)) ))
# Boxplots
ggplot(oxygen_data, aes(x=Bone, y=Oxygen_isotopic, group=Bone, fill=Bone)) +
geom_boxplot() +
labs(title="Oxygen isotopic composition of vertebrate bone phosphate",
x="Bone", y="Oxygen isotopic composition [per mil deviations from SMOW]") +
theme_classic()
# Perform the Kruskalâ€“Wallis test
kruskal.test(Oxygen_isotopic ~ Bone, data = oxygen_data)
# Post-hoc test
dunnTest(Oxygen_isotopic ~ Bone, data=oxygen_data, method="bh")
# Perform ANOVA
res_aov <- aov(Oxygen_isotopic ~ Bone, data=oxygen_data)
summary(res_aov)
library(MASS)
data(cpus)
fraction     <- 0.85
sample_index <- sample(nrow(cpus),nrow(cpus)*fraction)
cpus_train   <- cpus[sample_index,]
cpus_test    <- cpus[-sample_index,]
library(MASS)
data(cpus)
# Partitioning training (85%) and validation (15%) subsets
fraction     <- 0.85
sample_index <- sample(nrow(cpus),nrow(cpus)*fraction)
cpus_train   <- cpus[sample_index,]
cpus_test    <- cpus[-sample_index,]
cpus
# Plot scatter plots
ggpairs(cpus, columns=2:9)
library(ggplot2)
library(GGally)
library(olsrr)
# Plot scatter plots
ggpairs(cpus, columns=2:9)
# Load data
library(MASS)
data(cpus)
# Partitioning training (85%) and validation (15%) subsets
fraction        <- 0.85
sample_index    <- sample(nrow(cpus),nrow(cpus)*fraction)
cpus_training   <- cpus[sample_index,]
cpus_validation <- cpus[-sample_index,]
# Plot scatter plots
ggpairs(cpus_training, columns=2:9)
# Full model
model <- lm(perf  ~ syct   + mmin   + mmax  + cach + chmin + chmax, data = cpus_training)
model
full_model
# Full model
full_model <- lm(perf  ~ syct   + mmin   + mmax  + cach + chmin + chmax, data = cpus_training)
full_model
summary(full_model)
# Use the all possible subsets approach to find the best model
ols_step_all_possible(full_model)
ols_step_best_subset(full_model)
# 1.10 Best model
reg <- lm(perf  ~ syct   + mmin   + mmax  + cach + chmax, data = cpus_train)
summary(reg)
# Predicted individual CPU performance of the validation subset
pred <- predict(reg, cpus_validation,interval="prediction", level=0.95)
pred
# Compare
plot(pred[,1],cpus_validation$perf)
# Compare
plot(pred[,1],cpus_validation$perf, xlab="Predicted CPU performance",
ylab="Actual CPU performance")
# Check assumptions
par(mfrow = c(2, 2))
plot(reg)
par(mfrow = c(1, 1))
# Get Pearson correlation coefficient and relative mean bias
correlation <- cor(pred[,1],cpus_validation$perf)
# Get Pearson correlation coefficient and relative mean bias
cor(pred[,1],cpus_validation$perf)
# Get relative mean bias
Mean_bias <- mean(pred[,1]) - mean(cpus_validation$perf)
Mean_bias/mean(cpus_validation$perf)*100
# Best model
reg <- lm(perf  ~ syct   + mmin   + mmax  + cach + chmax, data = cpus_training)
pred <- predict(reg, cpus_validation, interval="prediction", level=0.95)
pred
# 1.12 Simulations
N_simulations     <- 50
correlation_all   <- c()
relative_bias_all <- c()
for(i in 1:N_simulations){
# Partitioning training (85%) and validation (15%) subsets
fraction        <- 0.85
sample_index    <- sample(nrow(cpus),nrow(cpus)*fraction)
cpus_training   <- cpus[sample_index,]
cpus_validation <- cpus[-sample_index,]
# Best model
reg <- lm(perf  ~ syct   + mmin   + mmax  + cach + chmax, data = cpus_training)
pred <- predict(reg, cpus_validation, interval="prediction", level=0.95)
# Get Pearson correlation coefficient and relative mean bias
cor_temp <- cor(pred[,1],cpus_validation$perf)
# Get relative mean bias
mean_bias          <- mean(pred[,1]) - mean(cpus_validation$perf)
relative_bias_temp <- mean_bias/mean(cpus_validation$perf)*100
# Store
correlation_all   <- c(correlation_all, cor_temp)
relative_bias_all <- c(relative_bias_all, relative_bias_temp)
}
correlation_all
relative_bias_all
hist(correlation_all)
hist(relative_bias_all)
vline(mean(correlation_all), col="red")
abline(v=mean(correlation_all), col="red")
abline(v=mean(correlation_all), col="red", lwd=2, type=2)
abline(v=mean(correlation_all), col="red", lwd=2, lty=2)
hist(correlation_all)
abline(v=mean(correlation_all), col="red", lwd=2)
hist(correlation_all)
abline(v=mean(correlation_all), col="red")
# Mean relative mean bias
hist(relative_bias_all)
abline(v=mean(relative_bias_all), col="blue")
mean(relative_bias_all)
mean(relative_bias_all)
mean(correlation_all)
mean(relative_bias_all) #
library(ggplot2)
library(GGally)
library(olsrr)
# Read ozone and meteorological data
Ozone_data <- read.csv(file = "ozone_data.csv", header=T)
# Check the data
str(Ozone_data)
# Plot scatter plots
ggpairs(Ozone_data, columns=1:5)
#----------------------------------------------------------------------
# Fit the full model, where all independent variables are included
full_model  <- lm(Ozone ~ Solar.Rad + Wind.Speed + Temperature + Pressure, data = Ozone_data)
# Test all possible subsets
output      <- ols_step_all_possible(full_model)
# Print results from all possible subsets
output
# Plot results from all possible subsets
plot(output)
#----------------------------------------------------------------------
ols_step_best_subset(full_model)
ols_step_backward_aic(full_model, details=F)
ols_step_forward_aic(full_model, details=F)
ols_step_both_aic(full_model, details=F)
#----------------------------------------------------------------------
# Best model
reg <- lm(Ozone ~ Solar.Rad + Wind.Speed + Temperature , data = Ozone_data)
summary(reg)
par(mfrow = c(2, 2))
plot(reg)
par(mfrow = c(1, 1))
# Make confidence band
predict(reg, interval="confidence", level=0.95)
# Make prediction band
predict(reg, interval="prediction", level=0.95)
#----------------------------------------------------------------------
# EX 1
# 1.1 Load data
library(MASS)
data(cpus)
# 1.2 Partitioning training (85%) and validation (15%) subsets
fraction        <- 0.85
sample_index    <- sample(nrow(cpus),nrow(cpus)*fraction)
cpus_training   <- cpus[sample_index,]
cpus_validation <- cpus[-sample_index,]
# 1.3 Plot scatter plots
ggpairs(cpus_training, columns=2:9)
# 1.4 Full model
full_model <- lm(perf  ~ syct   + mmin   + mmax  + cach + chmin + chmax, data = cpus_training)
summary(full_model)
# Variable selection
# 1.5 Use the all possible subsets approach to find the best model
ols_step_all_possible(full_model)
# 1.6 Use the all best subsets approach to find the best model
ols_step_best_subset(full_model)
# 1.7 Use backward elimination approach to find the best model.
ols_step_backward_aic(full_model)
# 1.8 Use forward selection approach to find the best model.
ols_step_forward_aic(full_model)
# 1.9 Use stepwise regression approach to find the best model.
ols_step_both_aic(full_model)
# 1.10 Best model
reg <- lm(perf  ~ syct   + mmin   + mmax  + cach + chmax, data = cpus_training)
summary(reg)
# Check assumptions
par(mfrow = c(2, 2))
plot(reg)
par(mfrow = c(1, 1))
# 1.11 Predicted individual CPU performance of the validation subset
pred <- predict(reg, cpus_validation,interval="prediction", level=0.95)
# Compare
plot(pred[,1],cpus_validation$perf, xlab="Predicted CPU performance",
ylab="Actual CPU performance")
# Get Pearson correlation coefficient and relative mean bias
cor(pred[,1],cpus_validation$perf)
# Get relative mean bias
mean_bias <- mean(pred[,1]) - mean(cpus_validation$perf)
mean_bias/mean(cpus_validation$perf)*100
# 1.12 Simulations
N_simulations     <- 50
correlation_all   <- c()
relative_bias_all <- c()
# Loop each simulation
for(i in 1:N_simulations){
# Create new subsets each time
# Partitioning training (85%) and validation (15%) subsets
fraction        <- 0.85
sample_index    <- sample(nrow(cpus),nrow(cpus)*fraction)
cpus_training   <- cpus[sample_index,]
cpus_validation <- cpus[-sample_index,]
# Using the same best model
reg <- lm(perf  ~ syct   + mmin   + mmax  + cach + chmax, data = cpus_training)
pred <- predict(reg, cpus_validation, interval="prediction", level=0.95)
# Get Pearson correlation coefficient and relative mean bias
cor_temp <- cor(pred[,1],cpus_validation$perf)
# Get relative mean bias
mean_bias          <- mean(pred[,1]) - mean(cpus_validation$perf)
relative_bias_temp <- mean_bias/mean(cpus_validation$perf)*100
# Store
correlation_all   <- c(correlation_all, cor_temp)
relative_bias_all <- c(relative_bias_all, relative_bias_temp)
}
# Mean Pearson correlation coefficient
hist(correlation_all)
abline(v=mean(correlation_all), col="red")
mean(correlation_all) # ~ 0.90, not bad
# Mean relative mean bias
hist(relative_bias_all)
abline(v=mean(relative_bias_all), col="blue")
mean(relative_bias_all) # ~ 0.5%, very good!
# 1.12 Simulations
N_simulations     <- 100000
correlation_all   <- c()
relative_bias_all <- c()
# Loop each simulation
for(i in 1:N_simulations){
# Create new subsets each time
# Partitioning training (85%) and validation (15%) subsets
fraction        <- 0.85
sample_index    <- sample(nrow(cpus),nrow(cpus)*fraction)
cpus_training   <- cpus[sample_index,]
cpus_validation <- cpus[-sample_index,]
# Using the same best model
reg <- lm(perf  ~ syct   + mmin   + mmax  + cach + chmax, data = cpus_training)
pred <- predict(reg, cpus_validation, interval="prediction", level=0.95)
# Get Pearson correlation coefficient and relative mean bias
cor_temp <- cor(pred[,1],cpus_validation$perf)
# Get relative mean bias
mean_bias          <- mean(pred[,1]) - mean(cpus_validation$perf)
relative_bias_temp <- mean_bias/mean(cpus_validation$perf)*100
# Store
correlation_all   <- c(correlation_all, cor_temp)
relative_bias_all <- c(relative_bias_all, relative_bias_temp)
}
# Mean Pearson correlation coefficient
hist(correlation_all)
abline(v=mean(correlation_all), col="red")
mean(correlation_all) # ~ 0.90, not bad
# Mean relative mean bias
hist(relative_bias_all)
abline(v=mean(relative_bias_all), col="blue")
mean(relative_bias_all) # ~ 1-2%, very good!
# 1.12 Simulations
N_simulations     <- 10000
correlation_all   <- c()
relative_bias_all <- c()
# Loop each simulation
for(i in 1:N_simulations){
# Create new subsets each time
# Partitioning training (85%) and validation (15%) subsets
fraction        <- 0.85
sample_index    <- sample(nrow(cpus),nrow(cpus)*fraction)
cpus_training   <- cpus[sample_index,]
cpus_validation <- cpus[-sample_index,]
# Using the same best model
reg <- lm(perf  ~ syct   + mmin   + mmax  + cach + chmax, data = cpus_training)
pred <- predict(reg, cpus_validation, interval="prediction", level=0.95)
# Get Pearson correlation coefficient and relative mean bias
cor_temp <- cor(pred[,1],cpus_validation$perf)
# Get relative mean bias
mean_bias          <- mean(pred[,1]) - mean(cpus_validation$perf)
relative_bias_temp <- mean_bias/mean(cpus_validation$perf)*100
# Store
correlation_all   <- c(correlation_all, cor_temp)
relative_bias_all <- c(relative_bias_all, relative_bias_temp)
}
# Mean Pearson correlation coefficient
hist(correlation_all)
abline(v=mean(correlation_all), col="red")
mean(correlation_all) # ~ 0.90, not bad
# Mean relative mean bias
hist(relative_bias_all)
abline(v=mean(relative_bias_all), col="blue")
mean(relative_bias_all) # ~ 1-2%, very good!
#library(InformationValue)
#library(pscl)
# Population per km2
Pop <- c(797,  3652,   384,   876,  1156,
5282,  3602,  4305,  6451, 939,
2725,   296,  1187,  4819,  7856,
1074,  1444,  2620,   417,  3232)
# PM exceeding
PM  <- c( 0,     1,    0,   0,   0,
1,     0,    1,   1,   1,
1,     0,    0,   0,   1,
0,     0,    1,   0,   1)
# Make a data frame
PM_data <- data.frame(Pop, PM)
str(PM_data)
# Fit the regression model
logistic <- glm( PM ~ Pop, data = PM_data, family = binomial)
# Print model detail
summary(logistic)
# Get McFaddenâ€™s R2
pR2(logistic)["McFadden"]
#library(InformationValue)
library(pscl)
# Get McFaddenâ€™s R2
pR2(logistic)["McFadden"]
# Find optimal cutoff probability to use to maximize accuracy
predicted_value <- predict(logistic, PM_data, type="response")
optimalCutoff(PM_data$PM, predicted_value)[1]
library(InformationValue)
# Find optimal cutoff probability to use to maximize accuracy
predicted_value <- predict(logistic, PM_data, type="response")
optimalCutoff(PM_data$PM, predicted_value)[1]
# Define new cities where we want to make predictions
new_cities <- data.frame(Pop = c(1000, 5000))
#predict probability of defaulting
predict(logistic, new_cities, type="response")
library(pscl)
library(InformationValue)
# Population per km2
Pop <- c(797,  3652,   384,   876,  1156,
5282,  3602,  4305,  6451, 939,
2725,   296,  1187,  4819,  7856,
1074,  1444,  2620,   417,  3232)
# PM exceeding
PM  <- c( 0,     1,    0,   0,   0,
1,     0,    1,   1,   1,
1,     0,    0,   0,   1,
0,     0,    1,   0,   1)
# Make a data frame
PM_data <- data.frame(Pop, PM)
str(PM_data)
# Fit the regression model
logistic <- glm( PM ~ Pop, data = PM_data, family = binomial)
# Print model detail
summary(logistic)
# Get McFaddenâ€™s R2
pR2(logistic)["McFadden"]
# Find optimal cutoff probability to use to maximize accuracy
predicted_value <- predict(logistic, PM_data, type="response")
optimalCutoff(PM_data$PM, predicted_value)[1]
# Define new cities where we want to make predictions
new_cities <- data.frame(Pop = c(1000, 5000))
#predict probability of defaulting
predict(logistic, new_cities, type="response")
library(pscl)
library(InformationValue)
# Population per km2
Pop <- c(797,  3652,   384,   876,  1156,
5282,  3602,  4305,  6451, 939,
2725,   296,  1187,  4819,  7856,
1074,  1444,  2620,   417,  3232)
# PM exceeding
PM  <- c( 0,     1,    0,   0,   0,
1,     0,    1,   1,   1,
1,     0,    0,   0,   1,
0,     0,    1,   0,   1)
# Make a data frame
PM_data <- data.frame(Pop, PM)
str(PM_data)
PM_data
# Fit the regression model
logistic <- glm( PM ~ Pop, data = PM_data, family = binomial)
# Print model detail
summary(logistic)
pR2(logistic)
predicted_value <- predict(logistic, PM_data, type="response")
predicted_value
optimalCutoff(PM_data$PM, predicted_value)[1]
optimalCutoff(PM_data$PM, predicted_value)
optimalCutoff(PM_data$PM, predicted_value)
# Define new cities where we want to make predictions
new_cities <- data.frame(Pop = c(1000, 5000))
#predict probability of defaulting
predict(logistic, new_cities, type="response")
PM_data
new_cities
PM_data
optimalCutoff(PM_data$PM, predicted_value)
# Define new cities where we want to make predictions
new_cities <- data.frame(Top = c(1000, 5000))
#predict probability of defaulting
predict(logistic, new_cities, type="response")
# Define new cities where we want to make predictions
new_cities <- data.frame(Pop = c(1000, 5000, 10000, 20))
#predict probability of defaulting
predict(logistic, new_cities, type="response")
# Define new cities where we want to make predictions
new_cities <- data.frame(Pop = c(300, 1500, 30000))
#predict probability of defaulting
predict(logistic, new_cities, type="response")
setwd("C://ese335")
rmarkdown::render_site()
rmarkdown::render_site()
# Read data
Keeling_Data     <- read.csv(file = "co2_mm_mlo.csv", header = T)
# Handel missing values
Keeling_Data$co2[which(Keeling_Data$co2<0)] <- NA
for(i in 1:length(Keeling_Data$co2)){
if( is.na(Keeling_Data$co2[i])){
Keeling_Data$co2[i] <- mean(Keeling_Data$co2[(i-2):(i+2)],na.rm=T )
}
}
# Apply the ts() function
co2 <- ts(Keeling_Data$co2, start=c(1958,3), frequency=12)
# Quick plot
plot(co2, type="l")
# Check the data type
str(co2)
co2_components <- decompose(co2)
plot(co2_components)
# Plot hist
hist(co2_components$random, prob=TRUE)
# Add a normal pdf curve
curve(dnorm(x, mean=mean(co2_components$random, na.rm=T),
sd=sd(co2_components$random, na.rm=T)),
add=TRUE, col="red")
# Make two panels
par(mfrow=c(2,1))
# ARIMA model (1,0,0)
plot(arima.sim(list(order=c(1,0,0), ar=.9), n=100), ylab="x",
main=(expression(AR(1)~~~phi==+.9)))
# ARIMA model (1,0,0)
plot(arima.sim(list(order=c(1,0,0), ar=-.9), n=100), ylab="x",
main=(expression(AR(1)~~~phi==-.9)))
# Make two panels
par(mfrow=c(2,1))
# ARIMA model (0,0,1)
plot(arima.sim(list(order=c(0,0,1), ma=.9), n=100), ylab="x",
main=(expression(MA(1)~~~theta==+.9)))
# ARIMA model (0,0,1)
plot(arima.sim(list(order=c(0,0,1), ma=-.9), n=100), ylab="x",
main=(expression(MA(1)~~~theta==-.9)))
# Compute ACF and PACF of AR(2)
ACF = ARMAacf(ar=c(1.5,-.75), ma=0, 24)[-1]
PACF = ARMAacf(ar=c(1.5,-.75), ma=0, 24, pacf=TRUE)
# Plot ACF and PACF of AR(2)
par(mfrow=c(1,2))
plot(ACF, type="h", xlab="lag", ylim=c(-.8,1)); abline(h=0)
plot(PACF, type="h", xlab="lag", ylim=c(-.8,1)); abline(h=0)
# Compute ACF and PACF of MA(2)
ACF = ARMAacf(ar=0, ma=c(0.5,0.6), 24)[-1]
PACF = ARMAacf(ar=0, ma=c(0.5,0.6), 24, pacf=TRUE)
# Plot ACF and PACF of MA(2)
par(mfrow=c(1,2))
plot(ACF, type="h", xlab="lag", ylim=c(-.8,1)); abline(h=0)
plot(PACF, type="h", xlab="lag", ylim=c(-.8,1)); abline(h=0)
# Load data
library(astsa)
# Plot
plot(globtemp, type="l", ylab="Global Temperature Deviations")
par(mfrow=c(1,1))
library(astsa)
# Plot
plot(globtemp, type="l", ylab="Global Temperature Deviations")
# Fit a linear model
trModel <- lm(globtemp ~ c(1:length(globtemp)))
# Get the residuals
residual <- resid(trModel)
# Plot the residual
plot(residual, type="l")
# Check acf anf pacf of the residuals
acf(residual)
pacf(residual)
setwd("C://ese335")
rmarkdown::render_site()
rmarkdown::render_site()
