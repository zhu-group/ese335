sample_index    <- sample(nrow(cpus),nrow(cpus)*fraction)
cpus_training   <- cpus[sample_index,]
cpus_validation <- cpus[-sample_index,]
# Using the same best model
reg <- lm(perf  ~ syct   + mmin   + mmax  + cach + chmax, data = cpus_training)
pred <- predict(reg, cpus_validation, interval="prediction", level=0.95)
# Get Pearson correlation coefficient and relative mean bias
cor_temp <- cor(pred[,1],cpus_validation$perf)
# Get relative mean bias
mean_bias          <- mean(pred[,1]) - mean(cpus_validation$perf)
relative_bias_temp <- mean_bias/mean(cpus_validation$perf)*100
# Store
correlation_all   <- c(correlation_all, cor_temp)
relative_bias_all <- c(relative_bias_all, relative_bias_temp)
}
# Mean Pearson correlation coefficient
hist(correlation_all)
abline(v=mean(correlation_all), col="red")
mean(correlation_all) # ~ 0.90, not bad
# 1.12 Simulations
N_simulations     <- 50
correlation_all   <- c()
relative_bias_all <- c()
# Loop each simulation
for(i in 1:N_simulations){
# Create new subsets each time
# Partitioning training (85%) and validation (15%) subsets
fraction        <- 0.85
sample_index    <- sample(nrow(cpus),nrow(cpus)*fraction)
cpus_training   <- cpus[sample_index,]
cpus_validation <- cpus[-sample_index,]
# Using the same best model
reg <- lm(perf  ~ syct   + mmin   + mmax  + cach + chmax, data = cpus_training)
pred <- predict(reg, cpus_validation, interval="prediction", level=0.95)
# Get Pearson correlation coefficient and relative mean bias
cor_temp <- cor(pred[,1],cpus_validation$perf)
# Get relative mean bias
mean_bias          <- mean(pred[,1]) - mean(cpus_validation$perf)
relative_bias_temp <- mean_bias/mean(cpus_validation$perf)*100
# Store
correlation_all   <- c(correlation_all, cor_temp)
relative_bias_all <- c(relative_bias_all, relative_bias_temp)
}
# Mean Pearson correlation coefficient
hist(correlation_all)
abline(v=mean(correlation_all), col="red")
mean(correlation_all) # ~ 0.90, not bad
# 1.12 Simulations
N_simulations     <- 50
correlation_all   <- c()
relative_bias_all <- c()
# Loop each simulation
for(i in 1:N_simulations){
# Create new subsets each time
# Partitioning training (85%) and validation (15%) subsets
fraction        <- 0.85
sample_index    <- sample(nrow(cpus),nrow(cpus)*fraction)
cpus_training   <- cpus[sample_index,]
cpus_validation <- cpus[-sample_index,]
# Using the same best model
reg <- lm(perf  ~ syct   + mmin   + mmax  + cach + chmax, data = cpus_training)
pred <- predict(reg, cpus_validation, interval="prediction", level=0.95)
# Get Pearson correlation coefficient and relative mean bias
cor_temp <- cor(pred[,1],cpus_validation$perf)
# Get relative mean bias
mean_bias          <- mean(pred[,1]) - mean(cpus_validation$perf)
relative_bias_temp <- mean_bias/mean(cpus_validation$perf)*100
# Store
correlation_all   <- c(correlation_all, cor_temp)
relative_bias_all <- c(relative_bias_all, relative_bias_temp)
}
# Mean Pearson correlation coefficient
hist(correlation_all)
abline(v=mean(correlation_all), col="red")
mean(correlation_all) # ~ 0.90, not bad
# Mean relative mean bias
hist(relative_bias_all)
abline(v=mean(relative_bias_all), col="blue")
mean(relative_bias_all) # 1-2%, very good!
# Mean relative mean bias
hist(relative_bias_all)
abline(v=mean(relative_bias_all), col="blue")
mean(relative_bias_all) # 1-2%, very good!
# Mean relative mean bias
hist(relative_bias_all)
abline(v=mean(relative_bias_all), col="blue")
mean(relative_bias_all) # 1-2%, very good!
library(ggplot2)
library(GGally)
library(olsrr)
# Read ozone and meteorological data
Ozone_data <- read.csv(file = "ozone_data.csv", header=T)
# Check the data
str(Ozone_data)
# Plot scatter plots
ggpairs(Ozone_data, columns=1:5)
#----------------------------------------------------------------------
# Fit the full model, where all independent variables are included
full_model  <- lm(Ozone ~ Solar.Rad + Wind.Speed + Temperature + Pressure, data = Ozone_data)
full_model
summary(full_model)
output      <- ols_step_all_possible(full_model)
# Print results from all possible subsets
output
output      <- ols_step_all_possible(full_model)
# Print results from all possible subsets
output
# Plot results from all possible subsets
plot(output)
# Plot results from all possible subsets
plot(output)
#----------------------------------------------------------------------
ols_step_best_subset(full_model)
ols_step_backward_aic(full_model, details=T)
ols_step_forward_aic(full_model, details=F)
ols_step_forward_aic(full_model, details=T)
ols_step_both_aic(full_model, details=F)
reg <- lm(Ozone ~ Solar.Rad + Wind.Speed + Temperature , data = Ozone_data)
summary(reg)
par(mfrow = c(2, 2))
plot(reg)
par(mfrow = c(1, 1))
par(mfrow = c(2, 2))
plot(reg)
par(mfrow = c(1, 1))
par(mfrow = c(2, 2))
plot(reg)
par(mfrow = c(1, 1))
# Make confidence band
predict(reg, interval="confidence", level=0.95)
# Make prediction band
predict(reg, interval="prediction", level=0.95)
q1 <- c(100, 50, 100, 100, 90, 98, 100, 100)
mean(q1)
sd(q1)
q2 <- c(85, 80, 100, 100, 75, 90, 100, 100)
mean(q2)
sd(q2)
q3 <- c(100, 90, 50, 80, 80, 80, 100, 100)
mean(q3)
sd(q3)
q4 <- c(100, 20, 20, 70, 70, 80, 90, 80)
mean(q4)
sd(q4)
install.packages("InformationValue")
install.packages("Rtools")
# Population per km2
Pop <- c(797,  3652,   384,   876,  1156,
5282,  3602,  4305,  6451, 939,
2725,   296,  1187,  4819,  7856,
1074,  1444,  2620,   417,  3232)
# PM exceeding
PM  <- c( 0,     1,    0,   0,   0,
1,     0,    1,   1,   1,
1,     0,    0,   0,   1,
0,     0,    1,   0,   1)
# Make a data frame
PM_data <- data.frame(Pop, PM)
str(PM_data)
# Fit the regression model
logistic <- glm( PM ~ Pop, data = PM_data, family = binomial)
# Print model detail
summary(logistic)
pR2(logistic)["McFadden"]
library(pscl)
pR2(logistic)["McFadden"]
# Find optimal cutoff probability to use to maximize accuracy
predicted_value <- predict(logistic, PM_data, type="response")
optimalCutoff(PM_data$PM, predicted_value)[1]
library(pscl)
library(InformationValue)
# Make a data frame
PM_data <- data.frame(Pop, PM)
str(PM_data)
# Fit the regression model
logistic <- glm( PM ~ Pop, data = PM_data, family = binomial)
# Print model detail
summary(logistic)
pR2(logistic)["McFadden"]
# Find optimal cutoff probability to use to maximize accuracy
predicted_value <- predict(logistic, PM_data, type="response")
optimalCutoff(PM_data$PM, predicted_value)[1]
# Define new cities where we want to make predictions
new_cities <- data.frame(Pop = c(1000, 5000))
#predict probability of defaulting
predict(logistic, new_cities, type="response")
# Add 5 cities to the Section Example
# Population per km2
Pop <- c(797,  3652,   384,   876,  1156,
5282,  3602,  4305,  6451, 939,
2725,   296,  1187,  4819,  7856,
1074,  1444,  2620,   417,  3232,
1988, 4000, 607, 5001, 7890)
# PM exceeding
PM  <- c( 0,     1,    0,   0,   0,
1,     0,    1,   1,   1,
1,     0,    0,   0,   1,
0,     0,    1,   0,   1,
0,     1,    0,   1,   1)
# Make a data frame
PM_data <- data.frame(Pop, PM)
str(PM_data)
# Fit the regression model
logistic <- glm( PM ~ Pop, data = PM_data, family = binomial)
# Print model detail
summary(logistic)
pR2(logistic)["McFadden"]
# Find optimal cutoff probability to use to maximize accuracy
predicted_value <- predict(logistic, PM_data, type="response")
optimalCutoff(PM_data$PM, predicted_value)[1]
# Define new cities where we want to make predictions
new_cities <- data.frame(Pop = c(300, 1500, 30000))
#predict probability of defaulting
predict(logistic, new_cities, type="response")
# Load libraries
library(dplyr)
library(lubridate)
library(forecast)
#-------------------------------------------------------------------------------
# 1. Load the daily new cases data
#-------------------------------------------------------------------------------
# Read in the COVID-19 data
COVID_data <- read.csv(file = "COVID_2020_data.csv", header = T)
# Check the variable names
head(COVID_data)
# Convert the data.frame to a tibble
COVID_tbl <- as_tibble(COVID_data)
COVID_tbl
#-------------------------------------------------------------------------------
# 2. Get the daily total number of newly reported cases worldwide
#-------------------------------------------------------------------------------
# Get global daily new cases
COVID_tbl <- COVID_tbl %>%
mutate(dateRep = as.Date(dateRep,format='%d/%m/%Y')) %>%
group_by(dateRep) %>%
summarize(global_cases = sum(cases))
# Show data
COVID_tbl
#-------------------------------------------------------------------------------
# 3. Plot the data
#-------------------------------------------------------------------------------
# Quick plot
plot(COVID_tbl$dateRep, COVID_tbl$global_cases,
type="l", xlab="Date", ylab="Global cases")
#-------------------------------------------------------------------------------
# 4. Filter the data
#-------------------------------------------------------------------------------
# Filter the data, only use data from April 01
COVID_tbl <- COVID_tbl %>%
filter(dateRep >= as.Date("2020-04-01"))
# Show data
COVID_tbl
#-------------------------------------------------------------------------------
# 5. Convert a vector to a time series
#-------------------------------------------------------------------------------
# Start date of the time series, read from the .csv file
Date_start <- as.Date("2020-04-01")
# End date of the time series, read from the .csv file
Date_end   <- as.Date("2020-11-09")
# Get the Julian Day of the start and end date
JD_start   <- yday(Date_start)
JD_end     <- yday(Date_end)
N_days     <- JD_end - JD_start + 1
# Convert the vector data to a time series
global_cases_ts <- ts(COVID_tbl$global_cases[1:N_days], start=c(2020,JD_start), frequency=365)
# The indicator of the time series
inds            <- seq(Date_start, Date_end, by="day")
# Check structure
str(global_cases_ts)
# Plot time series
plot(inds, global_cases_ts, type="l")
#-------------------------------------------------------------------------------
# 6. Transform the time series
#-------------------------------------------------------------------------------
# Data transform with log
global_cases_ts_log <- log(global_cases_ts)
# Plot time series
plot(inds, global_cases_ts_log, type="l")
# Check acf and pacf
acf(global_cases_ts_log)
pacf(global_cases_ts_log)
# Plot time series
plot(inds, global_cases_ts_log, type="l")
#-------------------------------------------------------------------------------
# 7. Take the difference
#-------------------------------------------------------------------------------
# Take the diff, d=1
global_cases_ts_log_d1 <- diff(global_cases_ts_log)
# Plot time series
plot(global_cases_ts_log_d1,type="l")
# Check acf and pacf
acf(global_cases_ts_log_d1)
pacf(global_cases_ts_log_d1)
#-------------------------------------------------------------------------------
# 8. Auto ARIMA fitting
#-------------------------------------------------------------------------------
# Automated forecasting using an ARIMA model
best_model <- auto.arima(global_cases_ts_log)
# Show details of the ARIMA model
best_model
# Number of days to predict
days_forecast  <- 30
# Number of include in the plot
days_in_plot   <- 30
# Make predictions using the forecast() function
forecast_30days <- forecast(best_model, days_forecast)
# Plot
plot(forecast(best_model, days_forecast), include=days_in_plot,
xlab="Time", ylab="log(global cases)", type="o", lwd=2)
#-------------------------------------------------------------------------------
# 10. Get predicted values
#-------------------------------------------------------------------------------
# Get predicted values on Nov 10, 2020
day_forward <- yday(as.Date("2020-11-10")) - yday(Date_end)
exp(forecast_30days$mean[day_forward])
exp(forecast_30days$lower[day_forward,1])
exp(forecast_30days$upper[day_forward,1])
# Get predicted values on Nov 30, 2020
day_forward <- yday(as.Date("2020-11-30")) - yday(Date_end)
exp(forecast_30days$mean[day_forward])
exp(forecast_30days$lower[day_forward,1])
exp(forecast_30days$upper[day_forward,1])
# Nov 10
(500063.9 - 502287)/502287 * 100
# Nov 30
(613331.2 - 516616)/516616 * 100
# Read data
COVID_data2 <- read.csv(file = "COVID_2020_data_new.csv", header = T)
COVID_tbl2 <- as_tibble(COVID_data2)
# Get global daily new cases
COVID_tbl2 <- COVID_tbl2 %>%
mutate(dateRep = as.Date(dateRep,format='%d/%m/%Y')) %>%
group_by(dateRep) %>%
summarize(global_cases = sum(cases))
# Real values at Nov 10 and 30
COVID_tbl2[COVID_tbl2$dateRep=="2020-11-10", ]
COVID_tbl2[COVID_tbl2$dateRep=="2020-11-30", ]
setwd("C://ese335")
rmarkdown::render_site()
rmarkdown::render_site()
# Section 19
# COVID-19 daily cases
# Load libraries
library(dplyr)
library(lubridate)
library(forecast)
#-------------------------------------------------------------------------------
# 1. Load the daily new cases data
#-------------------------------------------------------------------------------
# Read in the COVID-19 data
COVID_data <- read.csv(file = "COVID_2020_data.csv", header = T)
# Check the variable names
head(COVID_data)
# Convert the data.frame to a tibble
COVID_tbl <- as_tibble(COVID_data)
COVID_tbl
# Section 19
# COVID-19 daily cases
# Load libraries
library(dplyr)
library(lubridate)
library(forecast)
#-------------------------------------------------------------------------------
# 1. Load the daily new cases data
#-------------------------------------------------------------------------------
# Read in the COVID-19 data
COVID_data <- read.csv(file = "COVID_2020_data.csv", header = T)
# Check the variable names
head(COVID_data)
# Convert the data.frame to a tibble
COVID_tbl <- as_tibble(COVID_data)
COVID_tbl
COVID_tbl
# Section 19
# COVID-19 daily cases
# Load libraries
library(dplyr)
library(lubridate)
library(forecast)
#-------------------------------------------------------------------------------
# 1. Load the daily new cases data
#-------------------------------------------------------------------------------
# Read in the COVID-19 data
COVID_data <- read.csv(file = "COVID_2020_data.csv", header = T)
# Check the variable names
head(COVID_data)
# Convert the data.frame to a tibble
COVID_tbl <- as_tibble(COVID_data)
COVID_tbl
# Get global daily new cases
COVID_tbl <- COVID_tbl %>%
mutate(dateRep = as.Date(dateRep,format='%d/%m/%Y')) %>%
group_by(dateRep) %>%
summarize(global_cases = sum(cases))
# Show data
COVID_tbl
#-------------------------------------------------------------------------------
# 3. Plot the data
#-------------------------------------------------------------------------------
# Quick plot
plot(COVID_tbl$dateRep, COVID_tbl$global_cases,
type="l", xlab="Date", ylab="Global cases")
# Filter the data, only use data from April 01
COVID_tbl <- COVID_tbl %>%
filter(dateRep >= as.Date("2020-04-01"))
# Show data
COVID_tbl
#-------------------------------------------------------------------------------
# 4. Filter the data
#-------------------------------------------------------------------------------
# Filter the data, only use data from April 01
COVID_tbl <- COVID_tbl %>%
filter(dateRep >= as.Date("2020-04-01"))
# Show data
COVID_tbl
#-------------------------------------------------------------------------------
# 5. Convert a vector to a time series
#-------------------------------------------------------------------------------
# Start date of the time series, read from the .csv file
Date_start <- as.Date("2020-04-01")
# End date of the time series, read from the .csv file
Date_end   <- as.Date("2020-11-09")
# Get the Julian Day of the start and end date
JD_start   <- yday(Date_start)
JD_end     <- yday(Date_end)
N_days     <- JD_end - JD_start + 1
# Convert the vector data to a time series
global_cases_ts <- ts(COVID_tbl$global_cases[1:N_days], start=c(2020,JD_start), frequency=365)
# The indicator of the time series
inds            <- seq(Date_start, Date_end, by="day")
# Check structure
str(global_cases_ts)
# Plot time series
plot(inds, global_cases_ts, type="l")
# Data transform with log
global_cases_ts_log <- log(global_cases_ts)
# Plot time series
plot(inds, global_cases_ts_log, type="l")
# Check acf and pacf
acf(global_cases_ts_log)
pacf(global_cases_ts_log)
# Take the diff, d=1
global_cases_ts_log_d1 <- diff(global_cases_ts_log)
# Plot time series
plot(global_cases_ts_log_d1,type="l")
# Check acf and pacf
acf(global_cases_ts_log_d1)
pacf(global_cases_ts_log_d1)
# Automated forecasting using an ARIMA model
best_model <- auto.arima(global_cases_ts_log)
# Show details of the ARIMA model
best_model
# Number of days to predict
days_forecast  <- 30
# Number of include in the plot
days_in_plot   <- 30
# Make predictions using the forecast() function
forecast_30days <- forecast(best_model, days_forecast)
# Plot
plot(forecast(best_model, days_forecast), include=days_in_plot,
xlab="Time", ylab="log(global cases)", type="o", lwd=2)
# Number of days to predict
days_forecast  <- 30
# Number of include in the plot
days_in_plot   <- 20
# Make predictions using the forecast() function
forecast_30days <- forecast(best_model, days_forecast)
# Plot
plot(forecast(best_model, days_forecast), include=days_in_plot,
xlab="Time", ylab="log(global cases)", type="o", lwd=2)
# Number of days to predict
days_forecast  <- 30
# Number of include in the plot
days_in_plot   <- 10
# Make predictions using the forecast() function
forecast_30days <- forecast(best_model, days_forecast)
# Plot
plot(forecast(best_model, days_forecast), include=days_in_plot,
xlab="Time", ylab="log(global cases)", type="o", lwd=2)
# Number of days to predict
days_forecast  <- 30
# Number of include in the plot
days_in_plot   <- 30
# Make predictions using the forecast() function
forecast_30days <- forecast(best_model, days_forecast)
# Plot
plot(forecast(best_model, days_forecast), include=days_in_plot,
xlab="Time", ylab="log(global cases)", type="o", lwd=2)
# Get predicted values on Nov 10, 2020
day_forward <- yday(as.Date("2020-11-10")) - yday(Date_end)
exp(forecast_30days$mean[day_forward])
exp(forecast_30days$lower[day_forward,1])
exp(forecast_30days$upper[day_forward,1])
# Get predicted values on Nov 10, 2020
day_forward <- yday(as.Date("2020-11-10")) - yday(Date_end)
exp(forecast_30days$mean[day_forward])
exp(forecast_30days$lower[day_forward,1])
exp(forecast_30days$upper[day_forward,1])
# Get predicted values on Nov 30, 2020
day_forward <- yday(as.Date("2020-11-30")) - yday(Date_end)
exp(forecast_30days$mean[day_forward])
exp(forecast_30days$lower[day_forward,1])
exp(forecast_30days$upper[day_forward,1])
# Real values at Nov 10 and 30
COVID_tbl2[COVID_tbl2$dateRep=="2020-11-10", ]
COVID_tbl2[COVID_tbl2$dateRep=="2020-11-30", ]
# Real values at Nov 10 and 30
COVID_tbl2[COVID_tbl2$dateRep=="2020-11-10", ]
COVID_tbl2[COVID_tbl2$dateRep=="2020-11-30", ]
setwd("C://ese335")
rmarkdown::render_site()
rmarkdown::render_site()
