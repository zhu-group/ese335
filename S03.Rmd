---
title: "Section 03 Review of statistic basics (I)"
output:
  html_document:
    toc: true
    toc_float:
      collapsed: false
      smooth_scroll: false
---

***

***Pre-class reading:*** [RS] p1-22 

***

# Prerequisites

Install the following package:

+ `moments`

Load the libraries with R:
```{r}
library(moments)
```

***

# Section Example 1: How many hours do ESE335 student Sleep everyday?

This section starts with a poll. Suppose we want to know: on average how many hours ESE335 students sleep everyday will. To do so:

+ First, each student is assigned with and ID

+ Second, please think about your answer to the question. We will ask you later.

+ Now, we will ask 3 answers from you with random drawing.

***

# Population vs sample

From this simple poll, hopefully you have a clear understanding about:

+ Population. A *population* is a set of entities from which *statistical inferences* are to be drawn.

+ Sample. A *sample* is a set of data collected and/or selected from a population by a **defined procedure**. Here we draw samples through *simple random sampling*. 

***

# Statistical sleuthing 

Statistics is a common bond supporting all other sciences. It provides standards of **empirical proof** and a language for **communicating** scientific results. 

The first part is generally referred as **Statistical sleuthing**, which is the process of using statistical tools to answer questions of interest. It includes:

+ designing experiments to unearth hidden truths

+ describing real data using tools based on ideal mathematical models

+ answering the questions of interest efficiently

+ verifying that the tools are appropriate

+ snooping around to see if there is anything more to be learned.

***

# Standard Statistical Terminology

+ A *parameter* is an unknown numerical value describing a feature of a probability model. Parameters are indicated by Greek letters. 

+ A *statistic* is any quantity that can be calculated from the observed data. Statistics are represented by Roman letter symbols. 

+ An *estimate* is a statistic used as a guess for the value of a parameter. The notation for the estimate of a parameter is the parameter symbol with a hat on it.

***

# Statistics describing a sample

## Center

Call the `mean()` function to compute *average*.

## Spread

The *standard deviation* is a measure of spread, interpreted as the typical distance between a single number and the set’s average.

In R, standard deviation can be computed with the `sd()` function.

## Skewness

*Skewness* is a statistical numerical method to measure the *asymmetry* of the distribution or data set. It tells about the position of the majority of data values in the distribution around the mean value. Distributions can exhibit right (positive) skewness or left (negative) skewness to varying degrees. A normal distribution (bell curve) exhibits zero skewness.

Call the `skewness()` function in the `moments` package to compute the skewness.

## Kurtosis 

*Kurtosis* is a numerical method in statistics that measures the *sharpness* of the peak in the data distribution.

Call the `kurtosis()` function in the `moments` package to compute the kurtosis.

## Other statistics

We have covered many of the summary functions, make sure you understand what the following functions return: `median()`, `range()`, `max()`, `min()`, `var()`, `IQR()`, `summary()`. Pay attention to data sets containing `NA` values.

## An example

```{r}

# Drawing a sample (n=100) from a normal distribution
sample1 <- rnorm(n=100, mean=0, sd=1)

# OK, let's take a quick look at the data 
hist(sample1)

# Check the average and sd
mean(sample1)
sd(sample1)

# Compute the skewness, here we need load the moments package
library(moments)
skewness(sample1)

# Compute the kurtosis
kurtosis(sample1)

#--------------------------------
# Make a log-normal
sample2 <- exp(sample1+10)

# Check
hist(sample2)
mean(sample2)
sd(sample2)
skewness(sample2)
kurtosis(sample2)

```

***

# Section Example 2: Pirates vs. Global Warming

It’s official! The data’s been analyzed, and the true cause of global warming has finally been revealed: a worldwide crisis in declining pirate numbers. Don’t believe me? Well, there’s a graph to prove it.

<img src="figs/pirates_vs_T.jpg" alt="drawing" width="600"/>

[Figure Source](https://www.sisense.com/blog/global-warming-caused-lack-pirates-bad-graph-lessons/)

You can see that as the number of pirates in the world has decreased over the past 130 years, global warming has gotten steadily worse. In fact, this makes it entirely clear that if you truly want to stop global warming, the most impactful thing to do is - become a pirate!

Hope you're laughing. Unfortunately, this kind of ridiculous and **misleading causality** is sold wildly every day. 

***

# Causal inference and confunding variables

Statistical analysis **alone** can be used to establish a causal relationship, only if such a relationship is drawn from **randomized experiments**, but not from **observational studies**. The difference between randomized and observational studies is that whether the group status of the subjects can or can not be controlled by the investigator.

In an observational study, it is impossible to draw a causal conclusion from the statistical analysis alone, because one can not rule out the possibility that **confounding variables** are responsible for group differences in the measured outcome. So can you give some confounding variables in the Pirates vs. Global Warming example?

Observational studies are still very useful in research because:

+ Establishing causation is not always the goal

+ Establishing causation can be done in other ways

+ Observations may suggest an association

*** 

# Hypothesis tests

Briefly, hypothesis tests use data from a sample to infer the value of a population parameter. 

The first step in conducting a hypothesis test is to write the hypothesis statements that are going to be tested. For each test, you will have a **null hypothesis** (H~0~) and an **alternative hypothesis** (H~a~ or H~1~). In general, the null hypothesis is the one that specifies a simpler state of affairs, typically an absence of an effect.

The next step is to compute the **p-value**, which is defined as:

Given that the null hypothesis is true, a p-value is the probability that randomization alone leads to a test statistic **as extreme or more extreme** than the one observed.

Finally, we use the p-value to evaluate **statistical significance**. If we fail to reject the null hypothesis and there is no evidence to support the alternative hypothesis. These results are said to be not **statistically significant**. If then we reject the null hypothesis and conclude that there is evidence to support the alternative hypothesis. These results are statistically significant.

The general procedures are summarized:

+ Write the hypotheses

+ Construct a randomization distribution under the assumption that the null hypothesis is true

+ Use the randomization distribution to find the p-value

+ Decide if you should reject or fail to reject the null hypothesis

+ State a real-world conclusion in relation to the original research question

***

# In-class exercises

## Exercise #1

Can you create a left-skewed sample? Can you repeat we did in the above example?


## Exercise #2

One of the most important theorems in all of statistics is called the *Central Limit Theorem* or the *Law of Large Numbers*.  

It states that given a sufficiently large sample size from a population with a finite level of *variance*, the mean of all samples from the same population will be approximately equal to the mean of the original population. 

Furthermore, as you increase the number of samples and the sample size, the distribution of all of the sample means will approximate a normal distribution even if the original variables themselves are not normally distributed.

Can you demonstrate the two statements using R?