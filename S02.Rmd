---
title: "Section 02 Data wrangling and quick plots"
output:
  html_document:
    toc: true
    toc_float:
      collapsed: false
      smooth_scroll: false
---

***

# Prerequisites

Install the following packages:

+ `tidyr`
+ `dplyr`
+ `ggplot2`

Load the libraries with R:

```{r}
library(tidyr)
library(dplyr)
library(ggplot2)
```

***

# Section Example: weather data from BaoAn airport

Environment data, expecially raw observations, are really messy. Here we  take a look at  hourly weather data measured at BaoAn International Airport during the past 10 years. The data set is from [NOAA Integrated Surface Dataset](https://www.ncei.noaa.gov/products/land-based-station/integrated-surface-database).

Download the file [2281305.zip](https://zhu-group.github.io/ese335/download/2281305.zip), where the number `2281305` is the site ID.

Extract the zip file, you should see a file named `2281305.csv`. 

Open the file, you see many columns and even more lines, with no clear meaning and definitions. This is very often you would encounter when work with environmental data. As Hadley Wickham puts it, “Tidy datasets are all alike, but every messy dataset is messy in its own way.”  

***

*The notes below are modified from the excellent [Dataframe Manipulation](http://swcarpentry.github.io/r-novice-gapminder/) and freely available on the Software Carpentry website.*

***

# Loading a `.csv` file

<img src="figs/mlo_record.png" alt="drawing" width="800"/>

[Figure source](https://scrippsco2.ucsd.edu/history_legacy/keeling_curve_lessons.html)

[Charles David Keeling](https://scrippsco2.ucsd.edu/history_legacy/charles_david_keeling_biography.html) directed a program to measure the concentrations of CO~2~ in the atmosphere that continued without interruption from the late 1950s through the present. This program, operated out of [Scripps Institution of Oceanography](https://scripps.ucsd.edu), is responsible for the Mauna Loa record, which is almost certainly the **best-known icon** illustrating the impact of humanity on the planet as a whole. Learn more about [Keeling Curve Lessons](https://scrippsco2.ucsd.edu/history_legacy/keeling_curve_lessons.html).

We will start with [monthly CO~2~ data](https://www.esrl.noaa.gov/gmd/ccgg/trends/data.html) measured from Mauna Loa. 

To begin with,

+ Download the `co2_mm_mlo.csv` file from [here](https://zhu-group.github.io/ese335/download/co2_mm_mlo.csv)

+ Save the file to your `working directory`. 

+ Take a look at the file, where the column `co2` means monthly average CO~2~ in the unit of `ppm` (part per million, 10^-6^), `quality` column is the quality flag of the observation, `0` means the data point does not meet the quality control so that should be discarded, `1` means the data point is usable.

Now let's *load* this file via the following:

```{r}
Keeling_Data <- read.csv(file = "co2_mm_mlo.csv", header = T)
```

The file is loaded into the dataset `Keeling_Data`. Here we use the *option* `header = T` so that the first line of `co2_mm_mlo.csv` is also loaded as names of the variables. You can try to turn this off by setting `header = F`, and check what happens.

Check the names of columns:

```{r}
colnames(Keeling_Data)
```

If column names are not specified, *e.g.*, using `headers = FALSE` in a `read.csv()` function, R assigns default names `V1`, `V2`, ..., `Vn`.

Check the head (first 6 lines) of the dataset using `head()` function

```{r}
head(Keeling_Data)
```

Or the end of (last 6 lines) with `tail()`:

```{r}
tail(Keeling_Data)
```

The `read.table()` function is used for reading in **tabular data** stored in a text file where the columns of data are separated by punctuation characters such as `.csv` files (csv = comma-separated values). Tabular files are the most common *file type* you would encounter in your future study, as it's easy to use and share.

`Tabs` and `commas` are the most common punctuation characters used to separate or delimit data points in `.csv` files. For convenience R provides 2 other versions of `read.table()`. These are: `read.csv()` for files where the data are separated with `commas` and `read.delim()` for files where the data are separated with `tabs`. Of these three functions, `read.csv()` is the most commonly used. If needed it is possible to override the default delimiting punctuation marks for both `read.csv()` and `read.delim()`.

We can begin exploring our data set right away, pulling out columns by specifying them using the `$` operator:

```{r}
Keeling_Data$co2
```

Let's do some simple statistical checks with `Keeling_Data$co2`:

```{r}
# Min
min(Keeling_Data$co2)
# Max
max(Keeling_Data$co2)
# Range
range(Keeling_Data$co2)
# Mean
mean(Keeling_Data$co2)
# Median
median(Keeling_Data$co2)
# Show quantiles
summary(Keeling_Data$co2)
```

You will find there are some `-99.99` values, which are *missing values*. We will get back to this later.

You can use `[]` to extract elements of a vector by specifying their corresponding *index*.  

<font size="2" color="red"> **Important: **</font> Index in R starts from `1`, not `0`. For example:

```{r}
Keeling_Data$co2[1:10]
Keeling_Data$year[200:210]
Keeling_Data$co2[0]
```

# Tidy data

In the rest of the section, we will learn a consistent way to organize the data in R, called **tidy data**. Getting the data into this format requires some upfront work, but that work pays off in the long term. Once you have tidy data and the tools provided by the `tidyr`, `dplyr` and `ggplot2` packages, you will spend much less time munging/wrangling data from one representation to another, allowing you to spend more time on the analytic questions at hand.

## Tibble

For now, we will use `tibble` instead of R’s traditional `data.frame`. Tibble is a data frame, but they tweak some older behaviors to make life a little easier. 

Let's use `Keeling_Data` again:

```{r}
Keeling_Data <- read.csv(file = "co2_mm_mlo.csv", header = T)
head(Keeling_Data)
```

You can coerce a `data.frame` to a `tibble` using the `as_tibble()` function:

```{r}
Keeling_Data_tbl <- as_tibble(Keeling_Data)
Keeling_Data_tbl
```

## Tidy dataset

There are three inter-related rules which make a dataset tidy:

* Each variable must have its own column;
* Each observation must have its own row;
* Each value must have its own cell;

These three rules are interrelated because it’s impossible to only satisfy two of the three. 

That interrelationship leads to an even simpler set of practical instructions:

* Put each dataset in a tibble
* Put each variable in a column

Why ensure that your data is tidy? There are two main advantages:

* There’s a general advantage to picking one consistent way of storing data. If you have **a consistent data structure**, it’s easier to learn the tools that work with it because they have an **underlying uniformity**. If you ensure that your data is tidy, you’ll spend less time fighting with the tools and more time working on your analysis.

* There’s a specific advantage to placing variables in columns because it allows R’s **vectorized nature** to shine. That makes transforming tidy data feel particularly natural. `tidyr`, `dplyr`, and `ggplot2` are designed to work with tidy data.

***

# The `dplyr` package

The `dplyr` package provides a number of very useful functions for manipulating dataframes in a way that will reduce the self-repetition, reduce the probability of making errors, and probably even save you some typing. As an added bonus, you might even find the dplyr grammar easier to read.

Here we’re going to cover commonly used functions as well as using pipes `%>%` to combine them.

## Using `select()`

Use the `select()` function to keep only the variables (columns) you select.

```{r}
dplyr::select(Keeling_Data_tbl,year,co2,quality)
dplyr::select(Keeling_Data_tbl,co2)
```

## The pipe symbol `%>%`

Above we used ‘normal’ grammar, but the strengths of `dplyr` and `tidyr` lie in combining several functions using **pipes**. Since the pipes grammar is unlike anything we’ve seen in R before, let’s repeat what we’ve done above using pipes. 

`x %>% f(y)` is the same as `f(x, y)`

```{r}
Keeling_Data_tbl %>% 
  dplyr::select(year,co2,quality)
```

The above lines mean we first call the `Keeling_Data_tbl` tibble and pass it on, using the **pipe symbol** `%>%`, to the next step, which is the `select()` function. In this case, we don’t specify which **data object** we use in the `select()` function since in gets that from the previous pipe. The `select()` function then takes what it gets from the pipe, in this case the `Keeling_Data_tbl` tibble, as its **first argument**. By using pipe, we can take output of the previous step as input for the next one, so that we can avoid defining and calling unnecessary temporary variables. You will start to see the power of pipe later.

## Using `filter()`

Use `filter()` to get values (rows):
```{r}
Keeling_Data_tbl %>% 
  filter(year == 2000)
```

If we now want to move forward with the above tibble, but only with `quality == 1` , we can combine `select()` and `filter()` functions:
```{r}
Keeling_Data_tbl %>% 
  dplyr::select(year,co2,quality) %>% 
  filter(quality == 1)
```

You see here we have used the pipe twice, and the scripts become really clean and easy to follow. 

## Using `group_by()` and `summarize()`

Now try to group monthly data using the `group_by()` function, notice how the output tibble changes:

```{r}
Keeling_Data_tbl %>% 
  dplyr::select(year,month,co2,quality) %>% 
  filter(quality == 1) %>% 
  group_by(month)
```

The `group_by()` function is much more exciting in conjunction with the  `summarize()` function. This will allow us to create new variable(s) by using functions that repeat for each of the continent-specific data frames. That is to say, using the `group_by()` function, we **split our original dataframe into multiple pieces**, then we can run functions (*e.g.*, `mean()` or `sd()`) within `summarize()`.

```{r}
Keeling_Data_tbl %>% 
  dplyr::select(year,month,co2,quality) %>% 
  filter(quality == 1) %>% 
  group_by(month) %>% 
  summarize(monthly_mean = mean(co2))
```
Here we create a new variable (column) `monthly_mean`, and append it to the groups (`month` in this case). Now, we get a so-called *monthly climatology*.

You can also use `arrange()` and `desc()` to sort the data: 
```{r}
Keeling_Data_tbl %>% 
  dplyr::select(year,month,co2,quality) %>% 
  filter(quality == 1) %>% 
  group_by(month) %>% 
  summarize(monthly_mean = mean(co2)) %>% 
  arrange(monthly_mean)
```

```{r}
Keeling_Data_tbl %>% 
  dplyr::select(year,month,co2,quality) %>% 
  filter(quality == 1) %>% 
  group_by(month) %>% 
  summarize(monthly_mean = mean(co2)) %>% 
  arrange(desc(monthly_mean))
```

Let's add more statistics to the monthly climatology:
```{r}
Keeling_Data_tbl %>% 
  dplyr::select(year,month,co2,quality) %>% 
  filter(quality == 1) %>% 
  group_by(month) %>% 
  summarize(monthly_mean = mean(co2), monthly_sd = sd(co2),
            monthly_min = min(co2), monthly_max = max(co2),
            monthly_se = sd(co2)/sqrt(n()))
```
Here we call the `n()` to get the size of a vector.

## Using `mutate()`

We can also create new variables (columns) using the `mutate()` function. Here we create a new column `co2_ppb` by simply scaling `co2` by a factor of `1000`.

```{r}
Keeling_Data_tbl %>% 
  mutate(co2_ppb = co2 * 1e3)
```

When creating new variables, we can hook this with a logical condition. A simple combination of `mutate()` and `ifelse()` facilitates filtering right where it is needed: in the moment of creating something new. This easy-to-read statement is a fast and powerful way of discarding certain data or for updating values depending on this given condition. 

Let's create a new variable `co2_new`, it is equal to `co2` when `quality==1`, otherwise it's `NA`: 

```{r}
Keeling_Data_tbl %>% 
  mutate(co2_ppb = co2 * 1e3, co2_new = ifelse(quality==1, co2, NA))
```

## Combining `dplyr` and `ggplot2`

Just as we used `%>%` to pipe data along a chain of `dplyr` functions we can use it to pass data to `ggplot()`. Because `%>%` replaces **the first argument** in a function we don’t need to specify the `data = argument` in the `ggplot()` function. 

By combining `dplyr` and `ggplot2` functions, we can make figures without creating any new variables or modifying the data.

```{r}
Keeling_Data_tbl %>% 
  mutate(co2_new = ifelse(quality==1, co2, NA)) %>% 
  # Make the plot
  ggplot(aes(x=decimal_date, y=co2_new)) + 
  geom_line()
```

Let's plot CO~2~ of the same month as a function of `decimal_date`, with the `color` option:
```{r}
Keeling_Data_tbl %>% 
  mutate(co2_new = ifelse(quality==1, co2, NA)) %>% 
  # Make the plot
  ggplot(aes(x=decimal_date, y=co2_new, color=month)) + 
  geom_line()
```

Or plot the same data but in panels (facets), with the `facet_wrap` function:
```{r}
Keeling_Data_tbl %>% 
  mutate(co2_new = ifelse(quality==1, co2, NA)) %>% 
  # Make the plot
  ggplot(aes(x=decimal_date, y=co2_new, color=month)) + 
  geom_line() +
  facet_wrap(~ month)
```

OK, that is enough for data wrangling We will learn more about `ggplot2` in future sections.

***

# Quick plots

Now think about what will you do when get a new dataset before analyzing it?

Normally, we would like to do two things - to take a quick look at the statics and to plot the patterns. 

R has many built-in functions for a large number of summary statistics. For example,  `mean()`, `median()`, `range()`, `max()`, `min()`, `sd()`, `var()`, `IQR()`, and `summary()`. Make sure you understand how to use them and always pay attentions to `NA` values.

Our next task is to visualize the data. Often, a proper visualization can illuminate features of the data that can inform further analysis. We will learn three basic types of plots in this section.

## Histograms

When visualizing a single numerical variable, a histogram will be our go-to tool, which can be created in R using the `hist()` function.

```{r}
# Add a new column to the original tibble
Keeling_Data_tbl <- Keeling_Data_tbl %>% 
    mutate(co2_new = ifelse(quality==1, co2, NA))

# Notice we use pull() to get a vector from a tibble
Month_CO2 <- Keeling_Data_tbl %>% 
  pull(co2_new)

# plot hist
hist(Month_CO2)
```

The histogram function has a number of parameters which can be changed to make our plot look much nicer. Use the `?` operator to read the documentation for the `hist()` to see a full list of these parameters.

```{r}
hist(Month_CO2,
     xlab = "Monthly CO2 mixing ratios (ppm)",
     main = "Histogram of Monthly CO2",
     breaks = 20,
     col = "blue",
     border = "red")
box(lwd=2,col="green")
```

By default R will attempt to intelligently guess a good number of `breaks`, but as we can see here,
it is sometimes useful to modify this yourself.

## Boxplots

To visualize the relationship between a numerical and categorical variable, we will use a `boxplot`. A boxplot is usful in checking the center, spread, and skewness of a sample.

In the `Keeling_Data_tbl` dataset, the `month` is a categorical variable. First, note that we can use a single boxplot as an alternative to a histogram for visualizing a single numerical variable. To do so in R, we use the `boxplot()` function.

```{r}
boxplot(Month_CO2)
```

Or try to plot the raw data:

```{r}
boxplot(Keeling_Data$co2)
```

However, more often, we will use boxplots to compare a numerical variable for different values of a categorical variable.

```{r}
boxplot(co2_new ~ month, data=Keeling_Data_tbl)
```

Here we used the `boxplot()` command to create side-by-side boxplots. However, since we are now dealing with two variables, the syntax has changed. The R syntax `co2_new ~ month, data = Keeling_Data_tbl` reads “Plot the `co2_new` variable against the `month` variable using the `Keeling_Data_tbl` dataset.” We see the use of a `~` (which specifies a formula) and also a `data = argument`. This will be a syntax that is common to many functions we will use later.

Again, `boxplot()` has a number of additional arguments which have the ability to make our plot more visually appealing.

```{r}
boxplot(co2_new ~ month, data=Keeling_Data_tbl,
xlab = "Month",
ylab = "CO2 (ppm)",
main = "Monthly CO2",
cex = 2,
col = "orange",
border = "darkgreen")
```

## Scatterplots

Lastly, to visualize the relationship between two numeric variables, we will use a scatterplot. This can be done with the `plot()` function and the `~` syntax we just used with a boxplot. (The function `plot()` can also be used more generally; see the documentation for details.)

```{r}
plot(co2_new ~ year, data=Keeling_Data_tbl)
```

```{r}
plot(co2_new ~ year, data=Keeling_Data_tbl,
xlab = "Year",
ylab = "CO2 (ppm)",
main = "CO2 vs Year",
pch = "+",
cex = 2,
col = "navy")
```

***

# In-class exercises

## Exercise #1

Use `Keeling_Data`, compute the annual mean of CO~2~ since 1959, plot your results.

***

# Further reading

* [Data Wrangling with dplyr and tidyr Cheat Sheet](https://rstudio.com/wp-content/uploads/2015/02/data-wrangling-cheatsheet.pdf)
* [Dataframe Manipulation with dplyr](http://swcarpentry.github.io/r-novice-gapminder/13-dplyr/index.html)
* [Dataframe Manipulation with tidyr](http://swcarpentry.github.io/r-novice-gapminder/14-tidyr/index.html)
* [R for Data Science](https://r4ds.had.co.nz/), see chapter 10 and 12.
* [Data wrangling with R](https://rstudio.com/resources/webinars/data-wrangling-with-r-and-rstudio/), with a video
